{
 "PRed": [
  {
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.9.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/210175595.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/232820958.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/248639207.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/269277824.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/269407734.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.3post1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/292810739.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.3post2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/304897966.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.4"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/313994983.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.5"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/333351833.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.6"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/356658250.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.7"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/366187227.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python38"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/372230208.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.8"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/372628158.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.9"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/401630592.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.10"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/454885843.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.11"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/473557323.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.12"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/527807839.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.13"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/618713825.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.0.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/650190609.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.1.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/961589075.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python310"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  }
 ],
 "archived": false,
 "bad": "make_graph: render error No module named 'toml'\nTraceback (most recent call last):\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/feedstock_parser.py\", line 241, in populate_feedstock_attributes\n    parse_meta_yaml(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 167, in parse_meta_yaml\n    return _parse_meta_yaml_impl(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 239, in _parse_meta_yaml_impl\n    m = MetaData(tmpdir, config=config, variant=var)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 932, in __init__\n    self.parse_again(permit_undefined_jinja=True, allow_no_other_outputs=True)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1007, in parse_again\n    self.meta = parse(self._get_contents(permit_undefined_jinja,\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1546, in _get_contents\n    from conda_build.jinja_context import context_processor, UndefinedNeverFail, FilteredLoader\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/jinja_context.py\", line 13, in <module>\n    import toml\nModuleNotFoundError: No module named 'toml'\n",
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "airflow",
 "hash_type": "sha256",
 "name": "airflow-split",
 "new_version": "8.1.0",
 "new_version_attempts": {
  "1.10.10": 1,
  "1.10.11": 1,
  "1.10.12": 5,
  "1.10.13": 7,
  "1.10.14": 105,
  "2.0.0": 321,
  "2.0.1": 7,
  "2.0.2": 1,
  "2.1.0": 1,
  "4.0.0": 79,
  "4.1.0": 260,
  "6.4.0": 130,
  "8.1.0": 51
 },
 "new_version_errors": {
  "4.0.0": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '4.0.0' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://github.com/apache/{{ name }}/archive/{{ version }}.tar.gz'\n",
  "4.1.0": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '4.1.0' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://github.com/apache/{{ name }}/archive/{{ version }}.tar.gz'\n",
  "6.4.0": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '6.4.0' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://github.com/apache/{{ name }}/archive/{{ version }}.tar.gz'\n",
  "8.1.0": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '8.1.0' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://github.com/apache/{{ name }}/archive/{{ version }}.tar.gz'\n"
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "airflow",
   "airflow-with-apache-atlas",
   "airflow-with-apache-webhdfs",
   "airflow-with-async",
   "airflow-with-cgroups",
   "airflow-with-cncf-kubernetes",
   "airflow-with-dask",
   "airflow-with-deprecated-api",
   "airflow-with-github_enterprise",
   "airflow-with-google_auth",
   "airflow-with-kerberos",
   "airflow-with-ldap",
   "airflow-with-leveldb",
   "airflow-with-pandas",
   "airflow-with-password",
   "airflow-with-rabbitmq",
   "airflow-with-sentry",
   "airflow-with-statsd",
   "airflow-with-virtualenv",
   "apache-airflow"
  ]
 },
 "pinning_version": "2022.06.08.00.21.30",
 "pre_pr_migrator_attempts": {
  "version": 1
 },
 "pre_pr_migrator_status": {
  "version": "bot error: master: Traceback (most recent call last):\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/auto_tick.py\", line 1054, in main\n    migrator_uid, pr_json = run(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/auto_tick.py\", line 224, in run\n    eval_cmd(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 215, in eval_cmd\n    c = subprocess.run(\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/subprocess.py\", line 491, in run\n    stdout, stderr = process.communicate(input, timeout=timeout)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/subprocess.py\", line 1024, in communicate\n    stdout, stderr = self._communicate(input, endtime, timeout)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/subprocess.py\", line 1867, in _communicate\n    self._check_timeout(endtime, orig_timeout, stdout, stderr)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/subprocess.py\", line 1068, in _check_timeout\n    raise TimeoutExpired(\nsubprocess.TimeoutExpired: Command 'conda smithy rerender -c auto --no-check-uptodate' timed out after 300 seconds\n"
 },
 "raw_meta_yaml": "{% set name = \"airflow\" %}\n{% set version = \"2.3.3\" %}\n{% set sha256 = \"f32d27b9c9e5c3a87c5631011c321cb9f4e86b8f880209095fa36eb576bdc3a8\" %}\n\npackage:\n  name: {{ name|lower }}-split\n  version: {{ version }}\n\nsource:\n  fn: {{ name }}-{{ version }}.tar.gz\n  url: https://github.com/apache/{{ name }}/archive/{{ version }}.tar.gz\n  sha256: {{ sha256 }}\n\nbuild:\n  skip: true  # [win]\n  number: 1\n\noutputs:\n  - name: {{ name }}\n    script: install_airflow.sh\n    build:\n      entry_points:\n        - airflow=airflow.__main__:main\n    requirements:\n      host:\n        - python\n        - pip\n        # for md5sum, cksum, sha256sum\n        - coreutils\n        - docutils\n        - gitpython\n        - yarn\n        # seems to be having trouble with openssl 3.\n        # By including it as a dependency, we can explicitly check\n        - openssl\n      run:\n        - python\n        - alembic >=1.5.1,<2.0\n        - argcomplete >=1.10\n        - attrs >=20.0,<21.0\n        - blinker\n        - cached-property >=1.5  # [py<=37]\n        - cattrs >=1.1,<2,!=1.7.*\n        - colorlog >=4.0.2,<5.0\n        - connexion >=2.10.0\n\n        # connexion[swagger-ui] dependencies\n        - swagger-ui-bundle >=0.0.2,<0.1\n        # connexion[flask] dependencies\n        - flask >=1.0.4,<3\n        - itsdangerous >=0.24\n\n        - cron-descriptor >=1.2.24\n        - croniter >=0.3.17\n        - cryptography >=0.9.3\n        - deprecated >=1.2.13\n        - dill >=0.2.2\n        - flask >=2.0\n        - flask-appbuilder 4.1.2\n        - flask-caching >=1.5.0\n        - flask-login >=0.5\n        - flask-session >=0.4.0\n        - flask-wtf >=0.15\n        - python-graphviz >=0.12\n        - gunicorn >=19.5.0\n        - httpx\n        - importlib_metadata >=1.7  # [py<39]\n        - importlib_resources >=5.2  # [py<39]\n        - itsdangerous >=2.0\n        - jinja2 >=2.10.1\n        - jsonschema >=3.2.0\n        - lazy-object-proxy\n        - linkify-it-py >=2.0.0\n        - lockfile >=0.12.2\n        - markdown>=3.0\n        - markdown-it-py >=2.1.0\n        - markupsafe >=1.1.1\n        - marshmallow-oneofschema >=2.0.1\n        - mdit-py-plugins >=0.3.0\n        - packaging >=14.0\n        - pathspec >=0.9.0,<1.0\n        - pendulum >=2.0\n        - pluggy>=1.0\n        - psutil >=4.2.0\n        - pygments >=2.0.1\n        - pyjwt >=2.0.0\n        - python-daemon >=2.2.4\n        - python-dateutil >=2.3\n        - python-nvd3 >=0.15.0\n        - python-slugify >=5.0\n        - rich >=12.4.4\n        - setproctitle >=1.1.8\n        - sqlalchemy >=1.4\n        - sqlalchemy-jsonfield >=1.0\n        - tabulate >=0.7.5\n        - tenacity >=6.2.0\n        - termcolor >=1.1.0\n        - typing-extensions >=3.7.4\n        - unicodecsv >=0.14.1\n        - werkzeug >=2.0\n        - apache-airflow-providers-ftp\n        - apache-airflow-providers-http\n        - apache-airflow-providers-imap\n        - apache-airflow-providers-sqlite\n        # seems to be having trouble with openssl 3.\n        # By including it as a dependency, we can explicitly check\n        - openssl\n\n    test:\n      commands:\n        - pip check\n        - airflow --help\n        - airflow db init\n      imports:\n        - airflow\n        - airflow.api\n        - airflow.api.auth\n        - airflow.api.auth.backend\n        - airflow.api.client\n        - airflow.api.common\n        - airflow.api.common.experimental\n        - airflow.api_connexion\n        - airflow.cli\n        - airflow.cli.commands\n        - airflow.config_templates\n        - airflow.contrib\n        - airflow.contrib.hooks\n        - airflow.contrib.operators\n        - airflow.contrib.secrets\n        - airflow.contrib.sensors\n        - airflow.contrib.task_runner\n        - airflow.contrib.utils\n        - airflow.example_dags\n        - airflow.example_dags.subdags\n        - airflow.executors\n        - airflow.hooks\n        - airflow.jobs\n        - airflow.kubernetes\n        - airflow.lineage\n        - airflow.macros\n        - airflow.migrations\n        - airflow.migrations.versions\n        - airflow.models\n        - airflow.mypy\n        - airflow.mypy.plugin\n        - airflow.operators\n        - airflow.secrets\n        - airflow.security\n        - airflow.sensors\n        - airflow.serialization\n        - airflow.smart_sensor_dags\n        - airflow.task\n        - airflow.task.task_runner\n        - airflow.ti_deps\n        - airflow.ti_deps.deps\n        - airflow.utils\n        - airflow.utils.log\n        - airflow.www\n        - airflow.www.api\n        - airflow.www.api.experimental\n      requires:\n        - pip\n\n  # alternative name for the core package\n  - name: apache-airflow\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n    test:\n      imports:\n        - airflow\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-apache-atlas\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - atlasclient >=0.1.2\n    test:\n      imports:\n        - airflow.lineage\n        - airflow.lineage.entities\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-apache-webhdfs\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - python-hdfs >=2.0.4\n        - apache-airflow-providers-apache-hdfs\n    test:\n      imports:\n        - airflow\n        - hdfs\n        - airflow.hooks.webhdfs_hook\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-async\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - eventlet >=0.9.7\n        - gevent >=0.13\n        - greenlet >=0.4.9\n    test:\n      imports:\n        - airflow\n        - eventlet\n        - gevent\n        - greenlet\n      commands:\n        - pip check\n      requires:\n        - pip\n\n# this one isn't happy with openssl >=1.1.1n,<1.1.2a for some reason that\n# I can't reproduce easily with a local test\n#  - name: {{ name }}-with-celery\n#    requirements:\n#      host:\n#        - python\n#      run:\n#        - python\n#        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n#        - celery >=5.2.3,<6\n#        - flower >=1.0.0\n#    test:\n#      imports:\n#        - airflow\n#        - celery\n#      commands:\n#        - pip check\n#      requires:\n#        - pip\n\n  - name: {{ name }}-with-cgroups\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - cgroupspy >=0.2.2\n    test:\n      imports:\n        - airflow\n        - cgroupspy\n        - airflow.contrib.task_runner.cgroup_task_runner\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-cncf-kubernetes\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - cryptography >=2.0.0\n        - python-kubernetes >=21.7.0,<24\n    test:\n      imports:\n        - airflow\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-dask\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - cloudpickle >=1.4.1\n        - dask >=2.9.0\n        - distributed >=2.11.1\n    test:\n      imports:\n        - airflow\n        - distributed\n        - airflow.executors.dask_executor\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-deprecated-api\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - requests >=2.26.0\n    test:\n      imports:\n        - airflow\n      commands:\n        - pip check\n      requires:\n        - pip\n\n\n  - name: {{ name }}-with-github_enterprise\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - flask-appbuilder\n        # flask-appbuilder[oauth]\n        - authlib >=0.14,<1.0.0\n    test:\n      imports:\n        - airflow\n        - authlib\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-google_auth\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - flask-appbuilder\n        # flask-appbuilder[oauth]\n        - authlib >=0.14,<1.0.0\n    test:\n      imports:\n        - airflow\n        - authlib\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-kerberos\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - pykerberos >=1.1.13\n        - requests-kerberos >=0.10.0\n        - thrift_sasl >=0.2.0\n        # temporary dependencies because of bad build of thrift_sasl\n        - thrift >=0.13\n        - pure-sasl >=0.6.2\n        - six >=1.13.0\n    test:\n      imports:\n        - airflow\n        - kerberos\n        - airflow.api.auth.backend.kerberos_auth\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-ldap\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - ldap3 >=2.5.1\n        - python-ldap\n    test:\n      imports:\n        - airflow\n        - ldap3\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-leveldb\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - plyvel\n    test:\n      imports:\n        - airflow\n        - plyvel\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-pandas\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - pandas >=0.17.1\n    test:\n      imports:\n        - airflow\n        - pandas\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-password\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - bcrypt >=2.0.0\n        - flask-bcrypt >=0.7.1\n    test:\n      imports:\n        - airflow\n        - flask_bcrypt\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-rabbitmq\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - amqp\n    test:\n      imports:\n        - airflow\n        - amqp\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-sentry\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - blinker >=1.1\n        - sentry-sdk >=0.8.0\n    test:\n      imports:\n        - airflow\n        - sentry_sdk\n        - airflow.sentry\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-statsd\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - statsd >=3.3.0\n    test:\n      imports:\n        - airflow\n        - statsd\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: {{ name }}-with-virtualenv\n    requirements:\n      host:\n        - python\n      run:\n        - python\n        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}\n        - virtualenv\n    test:\n      imports:\n        - airflow\n        - virtualenv\n      commands:\n        - pip check\n      requires:\n        - pip\n\nabout:\n  home: http://airflow.apache.org\n  license: Apache-2.0\n  license_file: LICENSE\n  summary: |\n    Airflow is a platform to programmatically author, schedule and monitor\n    workflows\n\n  description: |\n    Use airflow to author workflows as directed acyclic graphs (DAGs)\n    of tasks. The airflow scheduler executes your tasks on an array of\n    workers while following the specified dependencies. Rich command\n    line utilities make performing complex surgeries on DAGs a snap.\n    The rich user interface makes it easy to visualize pipelines\n    running in production, monitor progress, and troubleshoot issues\n    when needed.\n\n    When workflows are defined as code, they become more maintainable,\n    versionable, testable, and collaborative.\n\n  doc_url: http://pythonhosted.org/airflow/profiling.html\n  dev_url: https://github.com/apache/airflow\n\nextra:\n  recipe-maintainers:\n    - sodre\n    - halldc\n    - xylar\n",
 "smithy_version": "3.20.0",
 "strong_exports": false,
 "url": "https://github.com/apache/airflow/archive/2.3.3.tar.gz",
 "version": "2.3.3"
}