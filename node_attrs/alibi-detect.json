{
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {
  "bot": {
   "automerge": true
  }
 },
 "feedstock_name": "alibi-detect",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "[Alibi Detect](https://github.com/SeldonIO/alibi-detect) is an open source\nPython library focused on **outlier**, **adversarial** and **drift** detection.\nThe package aims to cover both online and offline detectors for tabular data,\ntext, images and time series. Both **TensorFlow** and **PyTorch** backends are\nsupported for drift detection.\n\n- [Documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/)\n\nFor more background on the importance of monitoring outliers and distributions\nin a production setting, check out\n[this talk](https://slideslive.com/38931758/monitoring-and-explainability-of-models-in-production?ref=speaker-37384-latest)\nfrom the *Challenges in Deploying and Monitoring Machine Learning Systems*\nICML 2020 workshop, based on the paper [Monitoring and explainability of models\nin production](https://arxiv.org/abs/2007.06299) and referencing Alibi Detect.\n\nFor a thorough introduction to drift detection, check out [Protecting Your\nMachine Learning Against Drift: An Introduction](https://youtu.be/tL5sEaQha5o).\nhe talk covers what drift is and why it pays to detect it, the different types\nof drift, how it can be detected in a principled manner and also describes the\nanatomy of a drift detector.\n\n\nPyPI: [https://pypi.org/project/alibi-detect/](https://pypi.org/project/alibi-detect/)\n",
   "dev_url": "https://github.com/SeldonIO/alibi-detect",
   "doc_url": "https://docs.seldon.io/projects/alibi-detect/en/latest/",
   "home": "https://github.com/SeldonIO/alibi-detect",
   "license": "Apache-2.0",
   "license_file": "LICENSE",
   "summary": "Algorithms for outlier detection, concept drift and metrics."
  },
  "build": {
   "noarch": "python",
   "number": "1",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "sugatoray",
    "jklaise",
    "ascillitoe"
   ]
  },
  "package": {
   "name": "alibi-detect",
   "version": "0.8.1"
  },
  "requirements": {
   "host": [
    "pip",
    "python >=3.7"
   ],
   "run": [
    "python >=3.7",
    "dill >=0.3.0,<0.4.0",
    "matplotlib-base >=3.0.0,<4.0.0",
    "numba >=0.50.0,!=0.54.0,<0.56.0",
    "numpy >=1.16.2,<2.0.0",
    "opencv >=3.2.0,<5.0.0",
    "pandas >=0.23.3,<2.0.0",
    "pillow >=5.4.1,<9.0.0",
    "requests >=2.21.0,<3.0.0",
    "scikit-image >=0.14.2,!=0.17.1,<0.19",
    "scikit-learn >=0.20.2,<1.1.0",
    "scipy >=1.3.0,<2.0.0",
    "tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.8.0",
    "tensorflow-probability >=0.8.0,<0.13.0",
    "tqdm >=4.28.1,<5.0.0",
    "transformers >=4.0.0,<5.0.0",
    "absl-py >=0.10.0,<0.11.0",
    "wrapt >=1.12.1,<1.13.0",
    "libgdal"
   ]
  },
  "source": {
   "sha256": "329110ce128e68a940a35b93ebea086a3660964d88825e491f2319021e114035",
   "url": "https://pypi.io/packages/source/a/alibi-detect/alibi-detect-0.8.1.tar.gz"
  },
  "test": {
   "imports": [
    "alibi_detect"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "absl-py",
    "dill",
    "libgdal",
    "matplotlib-base",
    "numba",
    "numpy",
    "opencv",
    "pandas",
    "pillow",
    "python",
    "requests",
    "scikit-image",
    "scikit-learn",
    "scipy",
    "tensorflow",
    "tensorflow-probability",
    "tqdm",
    "transformers",
    "wrapt"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "description": "[Alibi Detect](https://github.com/SeldonIO/alibi-detect) is an open source\nPython library focused on **outlier**, **adversarial** and **drift** detection.\nThe package aims to cover both online and offline detectors for tabular data,\ntext, images and time series. Both **TensorFlow** and **PyTorch** backends are\nsupported for drift detection.\n\n- [Documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/)\n\nFor more background on the importance of monitoring outliers and distributions\nin a production setting, check out\n[this talk](https://slideslive.com/38931758/monitoring-and-explainability-of-models-in-production?ref=speaker-37384-latest)\nfrom the *Challenges in Deploying and Monitoring Machine Learning Systems*\nICML 2020 workshop, based on the paper [Monitoring and explainability of models\nin production](https://arxiv.org/abs/2007.06299) and referencing Alibi Detect.\n\nFor a thorough introduction to drift detection, check out [Protecting Your\nMachine Learning Against Drift: An Introduction](https://youtu.be/tL5sEaQha5o).\nhe talk covers what drift is and why it pays to detect it, the different types\nof drift, how it can be detected in a principled manner and also describes the\nanatomy of a drift detector.\n\n\nPyPI: [https://pypi.org/project/alibi-detect/](https://pypi.org/project/alibi-detect/)\n",
   "dev_url": "https://github.com/SeldonIO/alibi-detect",
   "doc_url": "https://docs.seldon.io/projects/alibi-detect/en/latest/",
   "home": "https://github.com/SeldonIO/alibi-detect",
   "license": "Apache-2.0",
   "license_file": "LICENSE",
   "summary": "Algorithms for outlier detection, concept drift and metrics."
  },
  "build": {
   "noarch": "python",
   "number": "1",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "sugatoray",
    "jklaise",
    "ascillitoe"
   ]
  },
  "package": {
   "name": "alibi-detect",
   "version": "0.8.1"
  },
  "requirements": {
   "host": [
    "pip",
    "python >=3.7"
   ],
   "run": [
    "python >=3.7",
    "dill >=0.3.0,<0.4.0",
    "matplotlib-base >=3.0.0,<4.0.0",
    "numba >=0.50.0,!=0.54.0,<0.56.0",
    "numpy >=1.16.2,<2.0.0",
    "opencv >=3.2.0,<5.0.0",
    "pandas >=0.23.3,<2.0.0",
    "pillow >=5.4.1,<9.0.0",
    "requests >=2.21.0,<3.0.0",
    "scikit-image >=0.14.2,!=0.17.1,<0.19",
    "scikit-learn >=0.20.2,<1.1.0",
    "scipy >=1.3.0,<2.0.0",
    "tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.8.0",
    "tensorflow-probability >=0.8.0,<0.13.0",
    "tqdm >=4.28.1,<5.0.0",
    "transformers >=4.0.0,<5.0.0",
    "absl-py >=0.10.0,<0.11.0",
    "wrapt >=1.12.1,<1.13.0",
    "libgdal"
   ]
  },
  "source": {
   "sha256": "329110ce128e68a940a35b93ebea086a3660964d88825e491f2319021e114035",
   "url": "https://pypi.io/packages/source/a/alibi-detect/alibi-detect-0.8.1.tar.gz"
  },
  "test": {
   "imports": [
    "alibi_detect"
   ]
  }
 },
 "name": "alibi-detect",
 "new_version": "0.8.1",
 "outputs_names": {
  "__set__": true,
  "elements": [
   "alibi-detect"
  ]
 },
 "raw_meta_yaml": "{% set name = \"alibi-detect\" %}\n{% set version = \"0.8.1\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/alibi-detect-{{ version }}.tar.gz\n  sha256: 329110ce128e68a940a35b93ebea086a3660964d88825e491f2319021e114035\n\nbuild:\n  number: 1\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python >=3.7\n  run:\n    - python >=3.7\n    - dill >=0.3.0,<0.4.0\n    - matplotlib-base >=3.0.0,<4.0.0\n    - numba >=0.50.0,!=0.54.0,<0.56.0\n    - numpy >=1.16.2,<2.0.0\n    - opencv >=3.2.0,<5.0.0\n    - pandas >=0.23.3,<2.0.0\n    - pillow >=5.4.1,<9.0.0\n    - requests >=2.21.0,<3.0.0\n    - scikit-image >=0.14.2,!=0.17.1,<0.19\n    - scikit-learn >=0.20.2,<1.1.0\n    - scipy >=1.3.0,<2.0.0\n    - tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.8.0\n    - tensorflow-probability >=0.8.0,<0.13.0\n    - tqdm >=4.28.1,<5.0.0\n    - transformers >=4.0.0,<5.0.0\n    # Necessary for passing pip-check\n    - absl-py >=0.10.0,<0.11.0\n    - wrapt >=1.12.1,<1.13.0\n    ## Note: Necessary for supporting \"opencv\"\n    #  A. \"mesa-libGL\" should be present in \"yum_requirements.txt\".\n    #  B. \"libgdal\" should be added to \"meta.yaml:requirements:run\".\n    - libgdal\n\ntest:\n  imports:\n    - alibi_detect\n  # commands:\n  #   - pip check\n  # requires:\n  #   - pip\n\nabout:\n  home: https://github.com/SeldonIO/alibi-detect\n  summary: Algorithms for outlier detection, concept drift and metrics.\n  license: Apache-2.0\n  license_file: LICENSE\n  description: |\n    [Alibi Detect](https://github.com/SeldonIO/alibi-detect) is an open source \n    Python library focused on **outlier**, **adversarial** and **drift** detection. \n    The package aims to cover both online and offline detectors for tabular data, \n    text, images and time series. Both **TensorFlow** and **PyTorch** backends are \n    supported for drift detection.\n\n    - [Documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/)\n\n    For more background on the importance of monitoring outliers and distributions \n    in a production setting, check out \n    [this talk](https://slideslive.com/38931758/monitoring-and-explainability-of-models-in-production?ref=speaker-37384-latest) \n    from the *Challenges in Deploying and Monitoring Machine Learning Systems* \n    ICML 2020 workshop, based on the paper [Monitoring and explainability of models \n    in production](https://arxiv.org/abs/2007.06299) and referencing Alibi Detect.\n\n    For a thorough introduction to drift detection, check out [Protecting Your \n    Machine Learning Against Drift: An Introduction](https://youtu.be/tL5sEaQha5o). \n    he talk covers what drift is and why it pays to detect it, the different types \n    of drift, how it can be detected in a principled manner and also describes the \n    anatomy of a drift detector.\n\n\n    PyPI: [https://pypi.org/project/alibi-detect/](https://pypi.org/project/alibi-detect/)\n\n  doc_url: https://docs.seldon.io/projects/alibi-detect/en/latest/\n  dev_url: https://github.com/SeldonIO/alibi-detect\n\nextra:\n  recipe-maintainers:\n    - sugatoray\n    # Maintainers from upstream repo\n    - jklaise\n    - ascillitoe\n",
 "req": {
  "__set__": true,
  "elements": [
   "absl-py",
   "dill",
   "libgdal",
   "matplotlib-base",
   "numba",
   "numpy",
   "opencv",
   "pandas",
   "pillow",
   "pip",
   "python",
   "requests",
   "scikit-image",
   "scikit-learn",
   "scipy",
   "tensorflow",
   "tensorflow-probability",
   "tqdm",
   "transformers",
   "wrapt"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "absl-py",
    "dill",
    "libgdal",
    "matplotlib-base",
    "numba",
    "numpy",
    "opencv",
    "pandas",
    "pillow",
    "python",
    "requests",
    "scikit-image",
    "scikit-learn",
    "scipy",
    "tensorflow",
    "tensorflow-probability",
    "tqdm",
    "transformers",
    "wrapt"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python >=3.7"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "absl-py >=0.10.0,<0.11.0",
    "dill >=0.3.0,<0.4.0",
    "libgdal",
    "matplotlib-base >=3.0.0,<4.0.0",
    "numba >=0.50.0,!=0.54.0,<0.56.0",
    "numpy >=1.16.2,<2.0.0",
    "opencv >=3.2.0,<5.0.0",
    "pandas >=0.23.3,<2.0.0",
    "pillow >=5.4.1,<9.0.0",
    "python >=3.7",
    "requests >=2.21.0,<3.0.0",
    "scikit-image >=0.14.2,!=0.17.1,<0.19",
    "scikit-learn >=0.20.2,<1.1.0",
    "scipy >=1.3.0,<2.0.0",
    "tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.8.0",
    "tensorflow-probability >=0.8.0,<0.13.0",
    "tqdm >=4.28.1,<5.0.0",
    "transformers >=4.0.0,<5.0.0",
    "wrapt >=1.12.1,<1.13.0"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": "https://pypi.io/packages/source/a/alibi-detect/alibi-detect-0.8.1.tar.gz",
 "version": "0.8.1"
}