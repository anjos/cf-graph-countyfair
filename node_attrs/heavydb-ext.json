{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/969454986.json"
   },
   "data": {
    "bot_rerun": 1658657512.6990352,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "tbb2021"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/969509512.json"
   },
   "data": {
    "bot_rerun": 1658666891.0329933,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python310"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/969539357.json"
   },
   "data": {
    "bot_rerun": 1658657512.699467,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "gdal35"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/969542867.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "geos3103"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/33b36777-5cc0-4629-bcb4-cead175cddf1.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "openssl3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/093f44f0-eb0b-4159-a892-5b1f56d4430a.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "arrow_cpp800"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/985609913.json"
   },
   "data": {
    "bot_rerun": 1658530620.2640386,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "geos3110"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/993676702.json"
   },
   "data": {
    "bot_rerun": 1658612359.4356549,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "fmt9"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/995424805.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "6.1.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1006217343.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "geos3110"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1006428350.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "fmt9"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1006549408.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy38"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1006552540.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python310"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1010138731.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "6.1.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1023365470.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "arrow_cpp900"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  }
 ],
 "archived": false,
 "bad": "make_graph: render error No module named 'toml'\nTraceback (most recent call last):\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/feedstock_parser.py\", line 241, in populate_feedstock_attributes\n    parse_meta_yaml(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 167, in parse_meta_yaml\n    return _parse_meta_yaml_impl(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 239, in _parse_meta_yaml_impl\n    m = MetaData(tmpdir, config=config, variant=var)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 932, in __init__\n    self.parse_again(permit_undefined_jinja=True, allow_no_other_outputs=True)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1007, in parse_again\n    self.meta = parse(self._get_contents(permit_undefined_jinja,\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1546, in _get_contents\n    from conda_build.jinja_context import context_processor, UndefinedNeverFail, FilteredLoader\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/jinja_context.py\", line 13, in <module>\n    import toml\nModuleNotFoundError: No module named 'toml'\n",
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "heavydb-ext",
 "hash_type": "sha256",
 "name": "heavydb-ext",
 "new_version": "6.1.1",
 "new_version_attempts": {
  "6.1.0": 2,
  "6.1.1": 1
 },
 "new_version_errors": {
  "6.1.0": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '6.1.0' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://github.com/heavyai/heavydb/archive/v{{ source_version }}.tar.gz'\n"
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "heavydb",
   "heavydb-common",
   "heavydbe",
   "pyheavydb",
   "pyheavydbe"
  ]
 },
 "pinning_version": "2022.08.11.00.12.17",
 "raw_meta_yaml": "{% set version = \"6.1.1\" %}  # PEP 386\n{% set source_version = version %}\n{% set base_version = version %}\n{% set number = \"0\" %}\n{% set cuda_enabled = cuda_compiler_version is not undefined and cuda_compiler_version == '11.0' %}\n{% set build_ext_version = \"1.0.0\" %}\n{% set build_ext = \"cuda\" if cuda_enabled else \"cpu\" %}\n{% set build_string = \"h{}_{}\".format(PKG_HASH, number) %}\n{% set build_string_ext = \"{}_{}\".format(build_string, build_ext) %}\n{% set py_build_string_ext = \"py{}{}_{}\".format(CONDA_PY, build_string, build_ext) %}\n{% set py_build_string = \"py{}{}\".format(CONDA_PY, build_string) %}\n{% set install_base = \"opt/heavyai\" %}\n{% set arrow_version = \"7.*\" %}\n{% set arrow_proc_version = \"3.*\" %}\n{% set pythrift_version = \"0.16.*\" %}\n{% set thrift_version = \"0.16.*\" %}\n# heavydb 6.1.0 is not LLVM 12 ready\n{% set llvm_version = \"11\" %}\n\npackage:\n  name: heavydb-ext\n  version: {{ version }}\n\nsource:\n  url: https://github.com/heavyai/heavydb/archive/v{{ source_version }}.tar.gz\n  sha256: 290079e636df1c359a48df2459fffd98defc4c36bb310134b08a9ddddf357c6c\n  patches:\n    - 0003-Fix-HeavyDBE-build.patch\n    - 0005-Fix-Windows-build-heavydb-610.patch  # [win]\n\nbuild:\n  number: {{ number }}\n  skip: true  # [cuda_compiler_version not in (undefined, \"None\", \"11.0\")]\n\noutputs:\n\n  - name: heavydb-common\n    version: {{ version }}\n    script: build-heavydb.sh  # [linux64]\n    script: build-heavydb-common.bat  # [win]\n    build:\n      string: {{ build_string }}\n      # cpu-only heavydb-common for cuda is required only for\n      # building cuda-enabled heavydb\n      skip: true  # [cuda_compiler_version not in (undefined, \"None\", \"11.0\")]\n      skip: true  # [osx]\n      skip: true  # [win and cuda_compiler_version != \"None\"]\n      run_exports:\n        - {{ pin_subpackage('heavydb-common',  max_pin='x.x.x') }}\n      ignore_run_exports:\n        - arrow-cpp {{ arrow_version }}\n        - blosc\n        - double-conversion\n        - fmt\n        - geos\n        - glog\n        - libarchive\n        - libgdal\n        - libllvm{{ llvm_version }}\n        - libpng\n        - librdkafka\n        - libstdcxx-ng\n        - libthrift\n    requirements:\n      build:\n        # c compiler is specified here to get run constraint pins correct, presumably...\n        - {{ compiler('c') }}\n        # go required for ThirdParty/generate_cert\n        - {{ compiler('cgo') }}\n        - {{ compiler('cxx') }}\n        - clangdev {{ llvm_version }}\n        # clang++ is used for generating the bytecodes of extension functions\n        - clangxx {{ llvm_version }}\n        - cmake\n        - llvmdev {{ llvm_version }}\n        - ninja\n        - maven\n      host:\n        # heavydb-common does not depend on build_ext, arrow-cpp\n        # (and other dependencies) is required just for the presence\n        # so that one could run cmake for generating *.bc, and other\n        # common data files.\n        - arrow-cpp ={{ arrow_version }}=*cpu\n        - bisonpp  # [unix]\n        - blosc\n        - boost-cpp\n        - clangdev {{ llvm_version }}\n        - double-conversion\n        - flex  # [unix]\n        - fmt\n        - geos\n        - glog\n        - llvmdev {{ llvm_version }}\n        - llvm {{ llvm_version }}\n        - libarchive\n        - libevent  # [win]\n        - libgdal\n        - libpng\n        - librdkafka\n        - tbb  # [win]\n        - tbb-devel  # [win]\n        - thrift-cpp {{ thrift_version }}\n        - winflexbison  # [win]\n    test:\n      commands:\n        # Test installation\n        # doc\n        - test -f ${PREFIX}/share/doc/heavyai/LICENSE.md  # [unix]\n        - if not exist %PREFIX%\\share\\doc\\heavyai\\LICENSE.md exit 1  # [win]\n        # data\n        - test -d ${PREFIX}/{{ install_base }}/ThirdParty/gdal-data  # [unix]\n        - if not exist %PREFIX%\\ThirdParty\\gdal-data exit 1  # [win]\n        # thrift\n        - test -f ${PREFIX}/{{ install_base }}/completion_hints.thrift  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/heavy.thrift  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/common.thrift  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/QueryEngine/serialized_result_set.thrift  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/QueryEngine/extension_functions.thrift  # [unix]\n        - if not exist %PREFIX%\\completion_hints.thrift exit 1  # [win]\n        - if not exist %PREFIX%\\heavy.thrift exit 1  # [win]\n        - if not exist %PREFIX%\\common.thrift exit 1  # [win]\n        - if not exist %PREFIX%\\QueryEngine/serialized_result_set.thrift exit 1  # [win]\n        - if not exist %PREFIX%\\QueryEngine/extension_functions.thrift exit 1  # [win]\n        # includes\n        - test -f ${PREFIX}/{{ install_base }}/Shared/funcannotations.h  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/Shared/InlineNullValues.h  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/Logger/Logger.h  # [unix]\n        - if not exist %PREFIX%\\Shared\\funcannotations.h exit 1  # [win]\n        - if not exist %PREFIX%\\Shared\\InlineNullValues.h exit 1  # [win]\n        - if not exist %PREFIX%\\Logger\\Logger.h exit 1  # [win]\n        # QE\n        - test -f ${PREFIX}/{{ install_base }}/QueryEngine/heavydbTypes.h  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/QueryEngine/RuntimeFunctions.bc  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/QueryEngine/GeosRuntime.bc  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/QueryEngine/ExtensionFunctions.ast  # [unix]\n        - if not exist %PREFIX%\\QueryEngine\\heavydbTypes.h exit 1  # [win]\n        - if not exist %PREFIX%\\QueryEngine\\RuntimeFunctions.bc exit 1  # [win]\n        - if not exist %PREFIX%\\QueryEngine\\GeosRuntime.bc exit 1  # [win]\n        - if not exist %PREFIX%\\QueryEngine\\ExtensionFunctions.ast exit 1  # [win]\n        # jar\n        - test -f ${PREFIX}/{{ install_base }}/bin/heavyai-utility-{{ base_version }}.jar  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/bin/heavyai-jdbc-{{ base_version }}.jar  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/bin/calcite-1.0-SNAPSHOT-jar-with-dependencies.jar  # [unix]\n        - if not exist %PREFIX%\\bin\\heavyai-utility-{{ base_version }}.jar exit 1  # [win]\n        - if not exist %PREFIX%\\bin\\heavyai-jdbc-{{ base_version }}.jar exit 1  # [win]\n        - if not exist %PREFIX%\\bin\\calcite-1.0-SNAPSHOT-jar-with-dependencies.jar exit 1  # [win]\n        # Unspecified\n        # startheavy and insert_sample_data are bash scripts\n        - test -f ${PREFIX}/{{ install_base }}/bin/startheavy  # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/bin/heavydb_insert_sample_data  # [unix]\n        #\n        - test -f ${PREFIX}/{{ install_base }}/bin/generate_cert  # [unix]\n        - if not exist %PREFIX%\\bin\\generate_cert exit 1  # [win]\n\n  - name: heavydb\n    version: {{ version }}\n    script: build-heavydb.sh   # [linux64]\n    script: build-heavydb.bat  # [win]\n    build:\n      string: {{ build_string_ext }}\n      skip: true  # [cuda_compiler_version not in (undefined, \"None\", \"11.0\")]\n      skip: true  # [osx]\n      skip: true  # [win and cuda_compiler_version != \"None\"]\n      missing_dso_whitelist:\n        - '*/libcuda.*'  # [cuda_compiler_version not in (undefined, \"None\")]\n      track_features:\n        {{ \"- arrow-cuda\" if cuda_enabled else \"\" }}\n      ignore_run_exports:\n        - cudatoolkit    # [cuda_compiler_version not in (undefined, \"None\")]\n        - fmt\n        - gflags\n        - glog\n        - libclang-cpp\n        - libkml\n        - ncurses\n        - openldap\n        - zlib\n      run_exports:\n        - {{ pin_subpackage('heavydb',  max_pin='x.x.x') }}\n    requirements:\n      build:\n        # c compiler is specified here to get run constraint pins correct, presumably..\n        - {{ compiler('c') }}\n        - {{ compiler('cgo') }}\n        - {{ compiler('cxx') }}\n        - {{ compiler(\"cuda\") }}  # [cuda_compiler_version not in (undefined, \"None\")]\n        - clangdev {{ llvm_version }}\n        # clang++ is used for generating the bytecodes of extension functions\n        - clangxx {{ llvm_version }}\n        - cmake\n        - llvmdev {{ llvm_version }}\n        - make\n        - ninja\n        - maven\n      host:\n        - arrow-cpp ={{ arrow_version }}=*{{ build_ext }}\n        - bisonpp  # [unix]\n        - blosc\n        - boost-cpp\n        - clangdev {{ llvm_version }}\n        - double-conversion\n        - flex  # [unix]\n        - fmt\n        - gflags\n        - glog\n        - llvmdev {{ llvm_version }}\n        - llvm {{ llvm_version }}\n        - libarchive\n        - libclang-cpp {{ llvm_version }}\n        - libevent  # [win]\n        - libgdal\n        - libkml\n        - libpng\n        - librdkafka\n        - libzlib\n        - ncurses   # [unix]\n        - openldap  # [unix]\n        # Workaround https://github.com/mamba-org/boa/issues/119 :\n        - openssl 1.1.1*\n        - snappy\n        - tbb\n        - tbb-devel\n        - thrift-cpp {{ thrift_version }}\n        - winflexbison  # [win]\n        - xerces-c\n      run:\n        - arrow-cpp-proc {{ arrow_proc_version }} {{ build_ext }}\n        - boost-cpp\n        - bzip2\n        # omnscidb Load-time UDF support calls clang++\n        - gxx_{{ target_platform }}  # [not win]\n        - libclang-cpp {{ llvm_version }}\n        - ncurses  # [not win]\n        - openjdk 8.*\n        - xz\n        - zlib\n        - {{ pin_subpackage('heavydb-common',  max_pin='x.x.x') }}\n      run_constrained:\n        - arrow-cpp-proc {{ arrow_proc_version }} {{ build_ext }}\n        - cudatoolkit >=11.0  # [cuda_compiler_version not in (undefined, \"None\")]\n\n    test:\n      commands:\n        # binary\n        - test -f ${PREFIX}/{{ install_base }}/bin/heavydb         # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/bin/initheavy       # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/bin/heavysql        # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/bin/KafkaImporter   # [unix]\n        - test -f ${PREFIX}/{{ install_base }}/bin/StreamImporter  # [unix]\n        - if not exist %PREFIX%\\bin\\heavydb.exe exit 1             # [win]\n        - if not exist %PREFIX%\\bin\\initheavy.exe exit 1           # [win]\n        - if not exist %PREFIX%\\bin\\heavysql.exe exit 1            # [win]\n\n        # Verify the activation scripts are in-place.\n        {% for state in [\"activate\", \"deactivate\"] %}\n        - test -f \"${PREFIX}/etc/conda/{{ state }}.d/{{ PKG_NAME }}_{{ state }}.sh\"  # [unix]\n        {% endfor %}\n        # Try using the activation scripts.\n        - |\n          if [[ -x \"$(command -v heavysql)\" ]]                                                 # [unix]\n          then                                                                                # [unix]\n            echo \"Found heavysql in PATH\"                                                     # [unix]\n          else                                                                                # [unix]\n            echo \"heavysql not found in PATH(=$PATH)\" && exit 1                               # [unix]\n          fi                                                                                  # [unix]\n          source ${PREFIX}/etc/conda/deactivate.d/{{ PKG_NAME }}_deactivate.sh                # [unix]\n          if [[ -x \"$(command -v heavysql)\" ]]                                                 # [unix]\n          then                                                                                # [unix]\n            echo \"Unexpectedly found heavysql in PATH(=$PATH) after deactivation\"  && exit 1  # [unix]\n          else                                                                                # [unix]\n            echo \"heavysql not in PATH after deactivation\"                                    # [unix]\n          fi                                                                                  # [unix]\n          source ${PREFIX}/etc/conda/activate.d/{{ PKG_NAME }}_activate.sh                    # [unix]\n        # Test installation\n        - heavysql -v              # [unix]\n        - which initheavy    # [unix]\n        - which heavydb    # [unix]\n        - heavysql.exe -v          # [win]\n        - |\n          if [ -x \"$(command -v nvidia-smi)\" ]; then  # [unix and cuda_compiler_version not in (undefined, \"None\")]\n            mkdir data && initheavy data              # [unix and cuda_compiler_version not in (undefined, \"None\")]\n            heavydb --version                         # [unix and cuda_compiler_version not in (undefined, \"None\")]\n            rm -rf data                               # [unix and cuda_compiler_version not in (undefined, \"None\")]\n          fi                                          # [unix and cuda_compiler_version not in (undefined, \"None\")]\n        - test -f ${PREFIX}/{{ install_base }}/QueryEngine/cuda_mapd_rt.fatbin  # [unix and cuda_compiler_version not in (undefined, \"None\")]\n        - test -f ${PREFIX}/{{ install_base }}/QueryEngine/CudaTableFunctions.a  # [unix and cuda_compiler_version not in (undefined, \"None\")]\n        # these are provided by heavydb-common package:\n        - which heavydb_insert_sample_data  # [unix]\n        - which startheavy  # [unix]\n\n    about:\n      home: https://heavy.ai\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: LICENSE.md\n      summary: The HeavyDB database\n\n      description: |\n        HeavyDB is an in-memory, column store, SQL relational database\n        that was designed from the ground up to run on GPUs.\n\n        This recipe provides both CUDA enabled and CUDA disabled heavydb\n        packages.\n      doc_url: https://docs.heavy.ai/\n      dev_url: https://github.com/heavyai/heavydb\n\n  - name: pyheavydb\n    version: {{ version }}\n    build:\n      skip: true  # [cuda_compiler_version in (\"11.0\",)]\n      noarch: python\n      script: python -m pip install -vv --no-deps python/.\n      run_exports:\n        - {{ pin_subpackage('pyheavydb',  max_pin='x.x.x') }}\n    requirements:\n      host:\n        - pip\n        - python\n        - flit-core\n      run:\n        - python >=3.7\n        - importlib_metadata\n        - packaging\n        - numpy >=1.16\n        - thrift {{ pythrift_version }}\n        - sqlalchemy >=1.3\n        - requests >=2.23.0\n\n    about:\n      home: https://github.com/heavyai/heavydb\n      license: Apache-2.0\n      license_family: Apache\n      license_file: ./python/LICENSE.md\n      summary: A python DB API 2 compatible client for HeavyDB (formerly OmniSci and MapD).\n      description: |\n        A python DB API 2 compatible client HeavyDB (formerly OmniSci and MapD).\n      doc_url: https://pyheavydb.readthedocs.io\n      dev_url: https://github.com/heavyai/heavydb\n\n    test:\n      imports:\n        - heavydb\n      commands:\n        - pip check\n      requires:\n        - pip\n\n  - name: heavydbe\n    version: {{ version }}\n    script: build-heavydb.sh\n    build:\n      string: {{ build_string_ext }}\n      skip: true  # [cuda_compiler_version not in (undefined, \"None\", \"11.0\") or not linux64]\n      skip: true\n      missing_dso_whitelist:\n        - '*/libcuda.*'  # [cuda_compiler_version not in (undefined, \"None\")]\n      track_features:\n        {{ \"- arrow-cuda\" if cuda_enabled else \"\" }}\n      ignore_run_exports:\n        - cudatoolkit    # [cuda_compiler_version not in (undefined, \"None\")]\n        - fmt\n        - glog\n        - libclang-cpp\n        - librdkafka\n        - ncurses\n        - zlib\n      rpaths:\n        - lib/\n        # fixes \"not found\" in `ldd $PREFIX/lib/libDBEngine.so` output\n        - {{ install_base }}/lib\n      run_exports:\n        - {{ pin_subpackage('heavydbe',  max_pin='x.x.x') }}\n    requirements:\n      build:\n        # c compiler is specified here to get run constraint pins correct, presumably..\n        - {{ compiler('c') }}\n        - {{ compiler('cgo') }}\n        - {{ compiler('cxx') }}\n        - {{ compiler(\"cuda\") }}  # [cuda_compiler_version not in (undefined, \"None\")]\n        - clangdev {{ llvm_version }}\n        # clang++ is used for generating the bytecodes of extension functions\n        - clangxx {{ llvm_version }}\n        - cmake\n        - llvmdev {{ llvm_version }}\n        - make\n        - ninja\n        - maven\n      host:\n        - arrow-cpp ={{ arrow_version }}=*{{ build_ext }}\n        - bisonpp\n        - blosc\n        - boost-cpp\n        - clangdev {{ llvm_version }}\n        - double-conversion\n        - flex\n        - fmt\n        - glog\n        - llvmdev {{ llvm_version }}\n        - llvm {{ llvm_version }}\n        - libarchive\n        - libclang-cpp {{ llvm_version }}\n        - libgdal\n        - libpng\n        - librdkafka\n        - libzlib\n        - tbb\n        - tbb-devel\n        - thrift-cpp {{ thrift_version }}\n        - xerces-c\n      run:\n        - arrow-cpp-proc {{ arrow_proc_version }} {{ build_ext }}\n        - boost-cpp\n        - bzip2\n        # omnscidb Load-time UDF support calls clang++\n        - gxx_{{ target_platform }}\n        - {{ pin_compatible('libclang-cpp', max_pin='x.x') }}\n        - ncurses\n        - openjdk 8.*\n        - xz\n        - zlib\n        - {{ pin_subpackage('heavydb-common',  max_pin='x.x.x') }}\n      run_constrained:\n        - arrow-cpp-proc {{ arrow_proc_version }} {{ build_ext }}\n        - cudatoolkit >=11.0  # [cuda_compiler_version not in (undefined, \"None\")]\n\n    test:\n      commands:\n        # Test installation\n        - test -f ${PREFIX}/lib/libDBEngine.so\n        # Verify the activation scripts are in-place.\n        {% for state in [\"activate\", \"deactivate\"] %}\n        - test -f \"${PREFIX}/etc/conda/{{ state }}.d/{{ PKG_NAME }}_{{ state }}.sh\"\n        {% endfor %}\n        - |\n          source ${PREFIX}/etc/conda/activate.d/{{ PKG_NAME }}_activate.sh\n          test -n \"${HEAVYAI_ROOT_PATH+x}\"\n          ldd ${PREFIX}/lib/libDBEngine.so\n\n    about:\n      home: https://heavy.ai\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: LICENSE.md\n      summary: The HeavyDB database\n\n      description: |\n        HeavyDB is an in-memory, column store, SQL relational database\n        that was designed from the ground up to run on GPUs.\n      doc_url: https://docs.heavy.ai/\n      dev_url: https://github.com/heavyai/heavydb\n\n  - name: pyheavydbe\n    version: {{ version }}\n    script: build-heavydb.sh\n    build:\n      string: {{ py_build_string_ext }}\n      skip: true  # [cuda_compiler_version not in (undefined, \"None\", \"11.0\") or not linux64]\n      skip: true  # temporarily skipping pyheavydbe build\n      missing_dso_whitelist:\n        - '*/libcuda.*'  # [cuda_compiler_version not in (undefined, \"None\")]\n      track_features:\n        {{ \"- arrow-cuda\" if cuda_enabled else \"\" }}\n      ignore_run_exports:\n        - arrow-cpp {{ arrow_version }}\n        - blosc\n        - cudatoolkit    # [cuda_compiler_version not in (undefined, \"None\")]\n        - double-conversion\n        - fmt\n        - glog\n        - libarchive\n        - libgdal\n        - libllvm{{ llvm_version }}\n        - libpng\n        - librdkafka\n        - libthrift {{ thrift_version }}\n        - pyarrow {{ arrow_version }}\n        - python\n        - tbb\n      run_exports:\n        - {{ pin_subpackage('pyheavydbe',  max_pin='x.x.x') }}\n    requirements:\n      build:\n        # c compiler is specified here to get run constraint pins correct, presumably..\n        - {{ compiler('c') }}\n        - {{ compiler('cgo') }}\n        - {{ compiler('cxx') }}\n        - {{ compiler(\"cuda\") }}  # [cuda_compiler_version not in (undefined, \"None\")]\n        - clangdev {{ llvm_version }}\n        # clang++ is used for generating the bytecodes of extension functions\n        - clangxx {{ llvm_version }}\n        - cmake\n        - llvmdev {{ llvm_version }}\n        - make\n        - ninja\n        - maven\n      host:\n        - arrow-cpp ={{ arrow_version }}=*{{ build_ext }}\n        - bisonpp\n        - blosc\n        - boost-cpp\n        - clangdev {{ llvm_version }}\n        - cython\n        - double-conversion\n        - flex\n        - fmt\n        - glog\n        - llvmdev {{ llvm_version }}\n        - llvm {{ llvm_version }}\n        - libarchive\n        - libgdal\n        - libpng\n        - librdkafka\n        - numpy\n        - pip\n        - pyarrow ={{ arrow_version }}=*{{ build_ext }}\n        - python\n        - pytest\n        - tbb\n        - tbb-devel\n        - thrift-cpp {{ thrift_version }}\n        - {{ pin_subpackage('heavydbe', exact=True) }}\n      run:\n        - arrow-cpp-proc {{ arrow_proc_version }} {{ build_ext }}\n        - pyarrow ={{ arrow_version }}=*{{ build_ext }}\n        - python\n        - tbb4py\n        - {{ pin_subpackage('heavydbe', exact=True) }}\n    test:\n      requires:\n        - pytest\n        - numpy\n        - pandas\n      imports:\n        - heavydbe\n      source_files:\n        - Embedded/test/test_exceptions.py\n      commands:\n        - pytest -sv Embedded/test/test_exceptions.py\n\n    about:\n      home: https://heavy.ai\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: LICENSE.md\n      summary: The HeavyDB database\n\n      description: |\n        HeavyDB is an in-memory, column store, SQL relational database\n        that was designed from the ground up to run on GPUs.\n      doc_url: https://docs.heavy.ai/\n      dev_url: https://github.com/heavyai/heavydb\n\nabout:\n  home: https://heavy.ai\n  license: Apache-2.0\n  license_family: APACHE\n  license_file: LICENSE.md\n  summary: The HeavyDB database\n\n  description: |\n    HeavyDB is an in-memory, column store, SQL relational database\n    that was designed from the ground up to run on GPUs.\n\n    This recipe provides the following packages:\n      heavydb-common CUDA-enabled heavydb, cpu and cuda builds\n      pyheavydb Python connector\n      heavydbe embedding library, cpu and cuda builds\n      pyheavydbe-embedded Python extension module\n  doc_url: https://docs.heavy.ai/\n  dev_url: https://github.com/heavyai/heavydb\n\nextra:\n  recipe-maintainers:\n    - guilhermeleobas\n    - pearu\n    - tupui\n    - andrewseidl\n    - jclay\n",
 "smithy_version": "3.21.1",
 "strong_exports": false,
 "url": "https://github.com/heavyai/heavydb/archive/v6.1.1.tar.gz",
 "version": "6.1.1"
}