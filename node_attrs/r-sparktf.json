{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/299533513.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "RBaseRebuild",
    "migrator_version": 0,
    "name": "r-base-3.6.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/413295691.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 2,
    "migrator_version": 0,
    "name": "r400"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/654254779.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "r410"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  }
 ],
 "archived": false,
 "bad": "make_graph: render error No module named 'toml'\nTraceback (most recent call last):\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/feedstock_parser.py\", line 241, in populate_feedstock_attributes\n    parse_meta_yaml(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 167, in parse_meta_yaml\n    return _parse_meta_yaml_impl(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 239, in _parse_meta_yaml_impl\n    m = MetaData(tmpdir, config=config, variant=var)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 932, in __init__\n    self.parse_again(permit_undefined_jinja=True, allow_no_other_outputs=True)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1007, in parse_again\n    self.meta = parse(self._get_contents(permit_undefined_jinja,\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1546, in _get_contents\n    from conda_build.jinja_context import context_processor, UndefinedNeverFail, FilteredLoader\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/jinja_context.py\", line 13, in <module>\n    import toml\nModuleNotFoundError: No module named 'toml'\n",
 "branch": "main",
 "conda-forge.yml": {
  "bot": {
   "automerge": true
  },
  "provider": {
   "win": "azure"
  }
 },
 "feedstock_name": "r-sparktf",
 "hash_type": "sha256",
 "name": "r-sparktf",
 "new_version": "0.1.0",
 "outputs_names": {
  "__set__": true,
  "elements": [
   "r-sparktf"
  ]
 },
 "pinning_version": "2021.05.25.06.47.12",
 "raw_meta_yaml": "{% set version = \"0.1.0\" %}\n{% set posix = 'm2-' if win else '' %}\n{% set native = 'm2w64-' if win else '' %}\n\npackage:\n  name: r-sparktf\n  version: {{ version|replace(\"-\", \"_\") }}\n\nsource:\n  url:\n    - {{ cran_mirror }}/src/contrib/sparktf_{{ version }}.tar.gz\n    - {{ cran_mirror }}/src/contrib/Archive/sparktf/sparktf_{{ version }}.tar.gz\n  sha256: a46bcb0b26636b87ee72047f54c18bbea2a1855c1d72b31b057894722c0aa049\n\nbuild:\n  merge_build_host: true  # [win]\n  number: 2\n  noarch: generic\n  rpaths:\n    - lib/R/lib/\n    - lib/\n\nrequirements:\n  build:\n    - {{ posix }}zip               # [win]\n  host:\n    - r-base\n    - r-sparklyr >=1.0\n  run:\n    - r-base\n    - r-sparklyr >=1.0\n\ntest:\n  commands:\n    - $R -e \"library('sparktf')\"           # [not win]\n    - \"\\\"%R%\\\" -e \\\"library('sparktf')\\\"\"  # [win]\n\nabout:\n  home: https://CRAN.R-project.org/package=sparktf\n  license: Apache-2.0\n  summary: A 'sparklyr' extension that enables reading and writing 'TensorFlow' TFRecord files via 'Apache Spark'.\n  license_family: APACHE\n  license_file: LICENSE-2.0.txt\n\nextra:\n  recipe-maintainers:\n    - conda-forge/r\n\n# Package: sparktf\n# Type: Package\n# Title: Interface for 'TensorFlow' 'TFRecord' Files with 'Apache Spark'\n# Version: 0.1.0\n# Authors@R: c( person(\"Kevin\", \"Kuo\", role = c(\"aut\", \"cre\"), email = \"kevin.kuo@rstudio.com\", comment = c(ORCID = \"0000-0001-7803-7901\")) )\n# Description: A 'sparklyr' extension that enables reading and writing 'TensorFlow' TFRecord files via 'Apache Spark'.\n# License: Apache License (>= 2.0)\n# Encoding: UTF-8\n# SystemRequirements: TensorFlow (https://www.tensorflow.org/)\n# LazyData: true\n# Depends: R (>= 3.1.2)\n# Imports: sparklyr (>= 1.0)\n# RoxygenNote: 6.1.0\n# Suggests: testthat, dplyr\n# NeedsCompilation: no\n# Packaged: 2019-02-26 22:12:47 UTC; kevinykuo\n# Author: Kevin Kuo [aut, cre] (<https://orcid.org/0000-0001-7803-7901>)\n# Maintainer: Kevin Kuo <kevin.kuo@rstudio.com>\n# Repository: CRAN\n# Date/Publication: 2019-03-05 14:30:03 UTC\n",
 "smithy_version": "3.10.1",
 "strong_exports": false,
 "url": [
  "https://cran.r-project.org/src/contrib/sparktf_0.1.0.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/sparktf/sparktf_0.1.0.tar.gz",
  "https://cran.r-project.org/src/contrib/sparktf_0.1.0.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/sparktf/sparktf_0.1.0.tar.gz"
 ],
 "version": "0.1.0"
}