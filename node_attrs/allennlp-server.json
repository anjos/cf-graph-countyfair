{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/841319634.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "OSXArm",
    "migrator_version": 1,
    "name": "arm osx addition"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  }
 ],
 "archived": false,
 "bad": "make_graph: render error No module named 'toml'\nTraceback (most recent call last):\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/feedstock_parser.py\", line 241, in populate_feedstock_attributes\n    parse_meta_yaml(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 167, in parse_meta_yaml\n    return _parse_meta_yaml_impl(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 239, in _parse_meta_yaml_impl\n    m = MetaData(tmpdir, config=config, variant=var)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 932, in __init__\n    self.parse_again(permit_undefined_jinja=True, allow_no_other_outputs=True)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1007, in parse_again\n    self.meta = parse(self._get_contents(permit_undefined_jinja,\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1546, in _get_contents\n    from conda_build.jinja_context import context_processor, UndefinedNeverFail, FilteredLoader\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/jinja_context.py\", line 13, in <module>\n    import toml\nModuleNotFoundError: No module named 'toml'\n",
 "branch": "main",
 "conda-forge.yml": {
  "build_platform": {
   "osx_arm64": "osx_64"
  }
 },
 "feedstock_name": "allennlp-server",
 "hash_type": "sha256",
 "name": "allennlp-server",
 "new_version": "1.0.0",
 "outputs_names": {
  "__set__": true,
  "elements": [
   "allennlp-server"
  ]
 },
 "pinning_version": "2022.02.07.00.17.20",
 "raw_meta_yaml": "{% set version = \"1.0.0\" %}\n\npackage:\n  name: allennlp-server\n  version: {{ version }}\n\nsource:\n  url: https://github.com/allenai/allennlp-server/archive/refs/tags/v{{ version }}.tar.gz\n  sha256: 2cb54ae493921a0225e780fb045c62de6f9b52b4c2f39cae51c01bc2def040d7\n\nbuild:\n  # strictly speaking, it should be possible to use noarch for this package;\n  # however, there have been unexplained segfaults in these packages (e.g. for py39),\n  # and for now it's better to run the test suite for all variants; once things\n  # have established themselves a while, reconsider this.\n  # noarch: python\n  number: 0\n  script: \"{{ PYTHON }} -m pip install . -vv\"\n  # currently missing windows / osx builds for allennlp >= 2.0\n  skip: true  # [win]\n\nrequirements:\n  build:\n    - python                                 # [build_platform != target_platform]\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n    - sysroot_linux-64 2.17   # [linux64]\n  host:\n    - python\n    - pip\n  run:\n    - python\n    - allennlp >=2.0,<3.0\n    - allennlp-models >=2.0,<3.0\n    - flask >=1.0.2\n    - flask-cors >=3.0.7\n    - gevent >=1.3.6\n\ntest:\n  requires:\n    - pytest\n    - spacy-model-en_core_web_sm\n  source_files:\n    - tests/\n  imports:\n    - allennlp_server\n  commands:\n    - pytest tests -v\n\nabout:\n  home: https://allennlp.org/\n  license: Apache-2.0\n  license_file: LICENSE\n  summary: A simple demo server for AllenNLP models. \n  dev_url: https://github.com/allenai/allennlp-server\n\nextra:\n  recipe-maintainers:\n    - dirkgr\n    - h-vetinari\n",
 "smithy_version": "3.16.2",
 "strong_exports": false,
 "url": "https://github.com/allenai/allennlp-server/archive/refs/tags/v1.0.0.tar.gz",
 "version": "1.0.0"
}