{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/715075615.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.0.55"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/715187693.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.0.56"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/719550856.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.0.57"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/721819623.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.0.58"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/722679878.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.0.59"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/745773625.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.0.60"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "pdpipe",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "Ever written a preprocessing pipeline for pandas dataframes and had trouble serializing it for later depoloyment on a different machine? Ever needed fit-able preprocessing transformations, that have tunable paramaters that are inferred from training data, to be used later to transform input data? Ever struggled with preprocessing different types of data in the same pandas dataframe? Enter pdpipe, a simple framework for serializable, chainable and verbose pandas pipelines. Its intuitive API enables you to generate, using only a few lines, complex pandas processing pipelines that can easily be broken down or composed together, examined and debugged, and that adhere to scikit-learn's Transformer API. Stop writing the same preprocessing boilerplate code again and again!\n",
   "dev_url": "https://github.com/pdpipe/pdpipe",
   "doc_url": "https://pdpipe.github.io/pdpipe/doc/pdpipe/",
   "home": "https://pdpipe.github.io/pdpipe/",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": "LICENSE.txt",
   "summary": "Easy pipelines for pandas."
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "Silun",
    "shaypal5"
   ]
  },
  "package": {
   "name": "pdpipe",
   "version": "0.0.59"
  },
  "requirements": {
   "host": [
    "python >=3.6,<3.9",
    "pip"
   ],
   "run": [
    "python >=3.6,<3.9",
    "pandas >=0.18.0",
    "sortedcontainers",
    "strct",
    "tqdm",
    "skutil >=0.0.15",
    "scikit-learn",
    "nltk"
   ]
  },
  "source": {
   "sha256": "a51a29bc7a8579da1a24a172778d1588767a1b3bcd4797dfba064b38802d7021",
   "url": "https://pypi.io/packages/source/p/pdpipe/pdpipe-0.0.59.tar.gz"
  },
  "test": {
   "imports": [
    "pdpipe"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "nltk",
    "pandas",
    "python",
    "scikit-learn",
    "skutil",
    "sortedcontainers",
    "strct",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "description": "Ever written a preprocessing pipeline for pandas dataframes and had trouble serializing it for later depoloyment on a different machine? Ever needed fit-able preprocessing transformations, that have tunable paramaters that are inferred from training data, to be used later to transform input data? Ever struggled with preprocessing different types of data in the same pandas dataframe? Enter pdpipe, a simple framework for serializable, chainable and verbose pandas pipelines. Its intuitive API enables you to generate, using only a few lines, complex pandas processing pipelines that can easily be broken down or composed together, examined and debugged, and that adhere to scikit-learn's Transformer API. Stop writing the same preprocessing boilerplate code again and again!\n",
   "dev_url": "https://github.com/pdpipe/pdpipe",
   "doc_url": "https://pdpipe.github.io/pdpipe/doc/pdpipe/",
   "home": "https://pdpipe.github.io/pdpipe/",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": "LICENSE.txt",
   "summary": "Easy pipelines for pandas."
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "Silun",
    "shaypal5"
   ]
  },
  "package": {
   "name": "pdpipe",
   "version": "0.0.59"
  },
  "requirements": {
   "host": [
    "python >=3.6,<3.9",
    "pip"
   ],
   "run": [
    "python >=3.6,<3.9",
    "pandas >=0.18.0",
    "sortedcontainers",
    "strct",
    "tqdm",
    "skutil >=0.0.15",
    "scikit-learn",
    "nltk"
   ]
  },
  "source": {
   "sha256": "a51a29bc7a8579da1a24a172778d1588767a1b3bcd4797dfba064b38802d7021",
   "url": "https://pypi.io/packages/source/p/pdpipe/pdpipe-0.0.59.tar.gz"
  },
  "test": {
   "imports": [
    "pdpipe"
   ]
  }
 },
 "name": "pdpipe",
 "new_version": "0.0.60",
 "new_version_attempts": {
  "0.0.55": 1,
  "0.0.56": 1,
  "0.0.57": 1,
  "0.0.58": 1,
  "0.0.59": 1,
  "0.0.60": 1
 },
 "new_version_errors": {},
 "outputs_names": {
  "__set__": true,
  "elements": [
   "pdpipe"
  ]
 },
 "pinning_version": "2021.09.28.19.51.35",
 "raw_meta_yaml": "{% set name = \"pdpipe\" %}\n{% set version = \"0.0.59\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: a51a29bc7a8579da1a24a172778d1588767a1b3bcd4797dfba064b38802d7021\n\nbuild:\n  noarch: python\n  number: 0\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - python >=3.6,<3.9\n    - pip\n  run:\n    - python >=3.6,<3.9\n    - pandas >=0.18.0\n    - sortedcontainers\n    - strct\n    - tqdm\n    - skutil >=0.0.15\n    - scikit-learn\n    - nltk\n\ntest:\n  imports:\n    - pdpipe\n\nabout:\n  home: https://pdpipe.github.io/pdpipe/\n  license: MIT\n  license_family: MIT\n  license_file: LICENSE.txt\n  summary: Easy pipelines for pandas.\n  doc_url: https://pdpipe.github.io/pdpipe/doc/pdpipe/\n  dev_url: https://github.com/pdpipe/pdpipe\n\n  description: |\n    Ever written a preprocessing pipeline for pandas dataframes and had trouble serializing it for later depoloyment on a different machine? Ever needed fit-able preprocessing transformations, that have tunable paramaters that are inferred from training data, to be used later to transform input data? Ever struggled with preprocessing different types of data in the same pandas dataframe? Enter pdpipe, a simple framework for serializable, chainable and verbose pandas pipelines. Its intuitive API enables you to generate, using only a few lines, complex pandas processing pipelines that can easily be broken down or composed together, examined and debugged, and that adhere to scikit-learn's Transformer API. Stop writing the same preprocessing boilerplate code again and again!\n\nextra:\n  recipe-maintainers:\n    - Silun\n    - shaypal5\n",
 "req": {
  "__set__": true,
  "elements": [
   "nltk",
   "pandas",
   "pip",
   "python",
   "scikit-learn",
   "skutil",
   "sortedcontainers",
   "strct",
   "tqdm"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "nltk",
    "pandas",
    "python",
    "scikit-learn",
    "skutil",
    "sortedcontainers",
    "strct",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "smithy_version": "3.12",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python >=3.6,<3.9"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "nltk",
    "pandas >=0.18.0",
    "python >=3.6,<3.9",
    "scikit-learn",
    "skutil >=0.0.15",
    "sortedcontainers",
    "strct",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": "https://pypi.io/packages/source/p/pdpipe/pdpipe-0.0.59.tar.gz",
 "version": "0.0.59"
}