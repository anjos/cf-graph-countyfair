{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/453665009.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/12038945-1025-4d84-88aa-973298bfa2d7.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python38"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/453848155.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/500788510.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.9.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/500933639.json"
   },
   "data": {
    "bot_rerun": 1605738941.0934641,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 2,
    "migrator_version": 0,
    "name": "python39"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/502927165.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.9.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/504255973.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.9.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/510331478.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.9.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/523506418.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.9.4"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/523561679.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 2,
    "migrator_version": 0,
    "name": "python39"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/551651453.json"
   },
   "data": {
    "bot_rerun": 1615299875.3172562,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy37"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/553812174.json"
   },
   "data": {
    "bot_rerun": 1615293437.303712,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.10.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/556208115.json"
   },
   "data": {
    "bot_rerun": 1615299875.3175626,
    "migrator_name": "ArchRebuild",
    "migrator_version": 1,
    "name": "aarch64 and ppc64le addition"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/569696429.json"
   },
   "data": {
    "bot_rerun": 1615293437.3040607,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.10.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/587926832.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.10.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/588062381.json"
   },
   "data": {
    "bot_rerun": 1632166101.3518183,
    "migrator_name": "ArchRebuild",
    "migrator_version": 1,
    "name": "aarch64 and ppc64le addition"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/588062753.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "OSXArm",
    "migrator_version": 1,
    "name": "arm osx addition"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/588077150.json"
   },
   "data": {
    "bot_rerun": 1632166101.3520715,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy37"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/609321118.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.10.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/651709821.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.10.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/737875077.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "ArchRebuild",
    "migrator_version": 1,
    "name": "aarch64 and ppc64le addition"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/737886358.json"
   },
   "data": {
    "bot_rerun": 1632201480.5507538,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy37"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/738374676.json"
   },
   "data": {
    "bot_rerun": 1640340750.2508357,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy37"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/773832671.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python310"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/809376917.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/811052086.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {
  "build_platform": {
   "osx_arm64": "osx_64"
  },
  "provider": {
   "linux_aarch64": "default",
   "linux_ppc64le": "default"
  }
 },
 "feedstock_name": "tokenizers",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/huggingface/tokenizers",
   "home": "https://pypi.org/project/tokenizers/",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "LICENSE",
   "summary": "Fast State-of-the-Art Tokenizers optimized for Research and Production"
  },
  "build": {
   "missing_dso_whitelist": [
    "/usr/lib64/libgcc_s.so.1",
    "/usr/lib64/libgcc_s.so.1",
    "/usr/lib64/libgcc_s.so.1"
   ],
   "number": "0",
   "script": [
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993"
   ]
  },
  "package": {
   "name": "tokenizers",
   "version": "0.11.1"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ],
   "host": [
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools"
   ],
   "run": [
    "python",
    "python",
    "python"
   ]
  },
  "source": {
   "sha256": "4edd36132b03d8a0c56f37bbc5fce5f8ee3558c9afaedee165516c5757271951",
   "url": "https://pypi.io/packages/source/t/tokenizers/tokenizers-0.11.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "pip check",
    "pip check"
   ],
   "imports": [
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations"
   ],
   "requires": [
    "pip",
    "pip",
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools",
    "setuptools-rust"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "linux_aarch64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/huggingface/tokenizers",
   "home": "https://pypi.org/project/tokenizers/",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "LICENSE",
   "summary": "Fast State-of-the-Art Tokenizers optimized for Research and Production"
  },
  "build": {
   "missing_dso_whitelist": [
    "/usr/lib64/libgcc_s.so.1",
    "/usr/lib64/libgcc_s.so.1",
    "/usr/lib64/libgcc_s.so.1"
   ],
   "number": "0",
   "script": [
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993"
   ]
  },
  "package": {
   "name": "tokenizers",
   "version": "0.11.1"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ],
   "host": [
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools"
   ],
   "run": [
    "python",
    "python",
    "python"
   ]
  },
  "source": {
   "sha256": "4edd36132b03d8a0c56f37bbc5fce5f8ee3558c9afaedee165516c5757271951",
   "url": "https://pypi.io/packages/source/t/tokenizers/tokenizers-0.11.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "pip check",
    "pip check"
   ],
   "imports": [
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations"
   ],
   "requires": [
    "pip",
    "pip",
    "pip"
   ]
  }
 },
 "linux_aarch64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools",
    "setuptools-rust"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "linux_ppc64le_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/huggingface/tokenizers",
   "home": "https://pypi.org/project/tokenizers/",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "LICENSE",
   "summary": "Fast State-of-the-Art Tokenizers optimized for Research and Production"
  },
  "build": {
   "missing_dso_whitelist": [
    "/usr/lib64/libgcc_s.so.1",
    "/usr/lib64/libgcc_s.so.1",
    "/usr/lib64/libgcc_s.so.1"
   ],
   "number": "0",
   "script": [
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993"
   ]
  },
  "package": {
   "name": "tokenizers",
   "version": "0.11.1"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ],
   "host": [
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools"
   ],
   "run": [
    "python",
    "python",
    "python"
   ]
  },
  "source": {
   "sha256": "4edd36132b03d8a0c56f37bbc5fce5f8ee3558c9afaedee165516c5757271951",
   "url": "https://pypi.io/packages/source/t/tokenizers/tokenizers-0.11.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "pip check",
    "pip check"
   ],
   "imports": [
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations"
   ],
   "requires": [
    "pip",
    "pip",
    "pip"
   ]
  }
 },
 "linux_ppc64le_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools",
    "setuptools-rust"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "dev_url": "https://github.com/huggingface/tokenizers",
   "home": "https://pypi.org/project/tokenizers/",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "LICENSE",
   "summary": "Fast State-of-the-Art Tokenizers optimized for Research and Production"
  },
  "build": {
   "missing_dso_whitelist": null,
   "number": "0",
   "script": [
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "export PYO3_CROSS_LIB_DIR=/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib",
    "find /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.* -name \"_sysconfigdata_*.py\" -type f -not -name \"_sysconfigdata_arm64_*.py\" -delete",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "export PYO3_CROSS_LIB_DIR=/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib",
    "find /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.* -name \"_sysconfigdata_*.py\" -type f -not -name \"_sysconfigdata_arm64_*.py\" -delete",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993"
   ]
  },
  "package": {
   "name": "tokenizers",
   "version": "0.11.1"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ],
   "host": [
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools"
   ],
   "run": [
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python"
   ]
  },
  "source": {
   "sha256": "4edd36132b03d8a0c56f37bbc5fce5f8ee3558c9afaedee165516c5757271951",
   "url": "https://pypi.io/packages/source/t/tokenizers/tokenizers-0.11.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check",
    "pip check"
   ],
   "imports": [
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations"
   ],
   "requires": [
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip",
    "pip"
   ]
  }
 },
 "name": "tokenizers",
 "new_version": "0.11.2",
 "new_version_attempts": {
  "0.10.0": 1,
  "0.10.1": 2,
  "0.10.2": 1,
  "0.10.3": 1,
  "0.11.0": 1,
  "0.11.1": 1,
  "0.8.1": 1,
  "0.9.0": 1,
  "0.9.1": 1,
  "0.9.2": 1,
  "0.9.3": 1,
  "0.9.4": 1
 },
 "new_version_errors": {},
 "osx_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/huggingface/tokenizers",
   "home": "https://pypi.org/project/tokenizers/",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "LICENSE",
   "summary": "Fast State-of-the-Art Tokenizers optimized for Research and Production"
  },
  "build": {
   "missing_dso_whitelist": [
    "/usr/lib/libresolv.9.dylib",
    "/usr/lib/libresolv.9.dylib",
    "/usr/lib/libresolv.9.dylib"
   ],
   "number": "0",
   "script": [
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993"
   ]
  },
  "package": {
   "name": "tokenizers",
   "version": "0.11.1"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ],
   "host": [
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools"
   ],
   "run": [
    "python",
    "python",
    "python"
   ]
  },
  "source": {
   "sha256": "4edd36132b03d8a0c56f37bbc5fce5f8ee3558c9afaedee165516c5757271951",
   "url": "https://pypi.io/packages/source/t/tokenizers/tokenizers-0.11.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "pip check",
    "pip check"
   ],
   "imports": [
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations"
   ],
   "requires": [
    "pip",
    "pip",
    "pip"
   ]
  }
 },
 "osx_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools",
    "setuptools-rust"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "osx_arm64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/huggingface/tokenizers",
   "home": "https://pypi.org/project/tokenizers/",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "LICENSE",
   "summary": "Fast State-of-the-Art Tokenizers optimized for Research and Production"
  },
  "build": {
   "missing_dso_whitelist": [
    "/usr/lib/libresolv.9.dylib",
    "/usr/lib/libresolv.9.dylib"
   ],
   "number": "0",
   "script": [
    "export PYO3_CROSS_LIB_DIR=/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib",
    "find /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.* -name \"_sysconfigdata_*.py\" -type f -not -name \"_sysconfigdata_arm64_*.py\" -delete",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv",
    "export PYO3_CROSS_LIB_DIR=/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib",
    "find /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.* -name \"_sysconfigdata_*.py\" -type f -not -name \"_sysconfigdata_arm64_*.py\" -delete",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993"
   ]
  },
  "package": {
   "name": "tokenizers",
   "version": "0.11.1"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ],
   "host": [
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools"
   ],
   "run": [
    "python",
    "python"
   ]
  },
  "source": {
   "sha256": "4edd36132b03d8a0c56f37bbc5fce5f8ee3558c9afaedee165516c5757271951",
   "url": "https://pypi.io/packages/source/t/tokenizers/tokenizers-0.11.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "pip check"
   ],
   "imports": [
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations"
   ],
   "requires": [
    "pip",
    "pip"
   ]
  }
 },
 "osx_arm64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools",
    "setuptools-rust"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "tokenizers"
  ]
 },
 "pinning_version": "2021.12.28.08.47.33",
 "raw_meta_yaml": "{% set name = \"tokenizers\" %}\n{% set version = \"0.11.1\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 4edd36132b03d8a0c56f37bbc5fce5f8ee3558c9afaedee165516c5757271951\n\nbuild:\n  number: 0\n  missing_dso_whitelist:\n    - /usr/lib/libresolv.9.dylib  # [osx]\n    - /usr/lib64/libgcc_s.so.1  # [linux]\n  script:\n    - export PYO3_CROSS_LIB_DIR={{ PREFIX }}/lib  # [arm64]\n    - find {{ PREFIX }}/lib/python3.* -name \"_sysconfigdata_*.py\" -type f -not -name \"_sysconfigdata_arm64_*.py\" -delete  # [arm64]\n    - {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  build:\n    - python                                 # [build_platform != target_platform]\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n    - {{ compiler('cxx') }}\n    - {{ compiler('rust') }}\n  host:\n    - python\n    - pip\n    - setuptools-rust >=0.11.5\n    - setuptools\n  run:\n    - python\n\ntest:\n  imports:\n    - tokenizers\n    - tokenizers.models\n    - tokenizers.decoders\n    - tokenizers.normalizers\n    - tokenizers.pre_tokenizers\n    - tokenizers.processors\n    - tokenizers.trainers\n    - tokenizers.implementations\n  commands:\n    - pip check\n  requires:\n    - pip\n\nabout:\n  home: https://pypi.org/project/tokenizers/\n  license: Apache-2.0\n  license_family: APACHE\n  license_file: LICENSE\n  summary: Fast State-of-the-Art Tokenizers optimized for Research and Production\n  dev_url: https://github.com/huggingface/tokenizers\n\nextra:\n  recipe-maintainers:\n    - anthchirp\n    - hadim\n    - ndmaxar\n    - oblute\n    - setu4993\n",
 "req": {
  "__set__": true,
  "elements": [
   "cxx_compiler_stub",
   "pip",
   "python",
   "rust_compiler_stub",
   "setuptools",
   "setuptools-rust"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "pip",
    "python",
    "setuptools",
    "setuptools-rust"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "smithy_version": "3.16.1",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools",
    "setuptools-rust >=0.11.5"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/t/tokenizers/tokenizers-0.11.1.tar.gz",
 "version": "0.11.1",
 "win_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/huggingface/tokenizers",
   "home": "https://pypi.org/project/tokenizers/",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "LICENSE",
   "summary": "Fast State-of-the-Art Tokenizers optimized for Research and Production"
  },
  "build": {
   "missing_dso_whitelist": null,
   "number": "0",
   "script": [
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv",
    "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993",
    "anthchirp",
    "hadim",
    "ndmaxar",
    "oblute",
    "setu4993"
   ]
  },
  "package": {
   "name": "tokenizers",
   "version": "0.11.1"
  },
  "requirements": {
   "build": [
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub",
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ],
   "host": [
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools",
    "python",
    "pip",
    "setuptools-rust >=0.11.5",
    "setuptools"
   ],
   "run": [
    "python",
    "python",
    "python"
   ]
  },
  "source": {
   "sha256": "4edd36132b03d8a0c56f37bbc5fce5f8ee3558c9afaedee165516c5757271951",
   "url": "https://pypi.io/packages/source/t/tokenizers/tokenizers-0.11.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "pip check",
    "pip check"
   ],
   "imports": [
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations",
    "tokenizers",
    "tokenizers.models",
    "tokenizers.decoders",
    "tokenizers.normalizers",
    "tokenizers.pre_tokenizers",
    "tokenizers.processors",
    "tokenizers.trainers",
    "tokenizers.implementations"
   ],
   "requires": [
    "pip",
    "pip",
    "pip"
   ]
  }
 },
 "win_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "cxx_compiler_stub",
    "rust_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools",
    "setuptools-rust"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 }
}