{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/336095445.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python38"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/393043131.json"
   },
   "data": {
    "bot_rerun": 1601641644.8880048,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/496879508.json"
   },
   "data": {
    "bot_rerun": 1601867677.1789336,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/497557556.json"
   },
   "data": {
    "bot_rerun": 1603216856.2445781,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/499531757.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "cuda110"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/507208299.json"
   },
   "data": {
    "bot_rerun": 1606157134.9305382,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/519072959.json"
   },
   "data": {
    "bot_rerun": 1606160259.6189694,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 2,
    "migrator_version": 0,
    "name": "python39"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/525889543.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "windows_cuda"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/527414614.json"
   },
   "data": {
    "bot_rerun": 1619109229.978521,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 2,
    "migrator_version": 0,
    "name": "python39"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/620690132.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "cuda111_112"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/621343233.json"
   },
   "data": {
    "bot_rerun": 1647755419.6842537,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 2,
    "migrator_version": 0,
    "name": "python39"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/836357875.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pytorch110"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/884393794.json"
   },
   "data": {
    "bot_rerun": 1649218563.870617,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python310"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/884901538.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pytorch111"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/901007657.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python310"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1000487784.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pytorch112"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1179488206.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python311"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/fbb8388b-7f99-4496-b065-88eb7fda8fcc.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pytorch113"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "nvidia-apex",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/NVIDIA/apex",
   "doc_url": "https://nvidia.github.io/apex/",
   "home": "https://nvidia.github.io/apex/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": "LICENSE",
   "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
  },
  "build": {
   "number": "1"
  },
  "extra": {
   "feedstock-name": "nvidia-apex",
   "recipe-maintainers": [
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14"
   ]
  },
  "outputs": [
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cuda"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cuda112py311h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cuda*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "nvidia-apex-proc =*=cuda|=*=gpu",
      "nvidia-apex-proc =*=cpu",
      "pytorch =*=cuda*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cpu"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cpu_py311h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cpu*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "pytorch =*=cpu*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cuda"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cuda112py38h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cuda*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "nvidia-apex-proc =*=cuda|=*=gpu",
      "nvidia-apex-proc =*=cpu",
      "pytorch =*=cuda*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cpu"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cpu_py310h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cpu*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "pytorch =*=cpu*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cpu"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cpu_py38h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cpu*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "pytorch =*=cpu*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cuda"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cuda112py310h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cuda*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "nvidia-apex-proc =*=cuda|=*=gpu",
      "nvidia-apex-proc =*=cpu",
      "pytorch =*=cuda*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cpu"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cpu_py39h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cpu*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "pytorch =*=cpu*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cuda"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cuda112py39h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cuda*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "nvidia-apex-proc =*=cuda|=*=gpu",
      "nvidia-apex-proc =*=cpu",
      "pytorch =*=cuda*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   }
  ],
  "package": {
   "name": "nvidia-apex-split",
   "version": "22.03"
  },
  "source": {
   "sha256": "694f1ac1aaed6435b2f0c2ebc1af56b8a215a5eaa96c2565a578e8734378ff66",
   "url": "https://github.com/NVIDIA/apex/archive/refs/tags/22.03.tar.gz"
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cuda_compiler_stub",
    "cxx_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "pytorch",
    "setuptools"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cxxfilt",
    "numpy",
    "pytest",
    "python",
    "pyyaml",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "dev_url": "https://github.com/NVIDIA/apex",
   "doc_url": "https://nvidia.github.io/apex/",
   "home": "https://nvidia.github.io/apex/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": "LICENSE",
   "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
  },
  "build": {
   "number": "1"
  },
  "extra": {
   "feedstock-name": "nvidia-apex",
   "recipe-maintainers": [
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14",
    "h-vetinari",
    "oblute",
    "benhuff",
    "jakirkham",
    "rluria14"
   ]
  },
  "outputs": [
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cuda"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cuda112py311h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cuda*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "nvidia-apex-proc =*=cuda|=*=gpu",
      "nvidia-apex-proc =*=cpu",
      "pytorch =*=cuda*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cpu"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cpu_py311h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cpu*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "pytorch =*=cpu*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cuda"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cuda112py38h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cuda*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "nvidia-apex-proc =*=cuda|=*=gpu",
      "nvidia-apex-proc =*=cpu",
      "pytorch =*=cuda*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cpu"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cpu_py310h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cpu*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "pytorch =*=cpu*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cpu"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cpu_py38h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cpu*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "pytorch =*=cpu*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cuda"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cuda112py310h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cuda*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "nvidia-apex-proc =*=cuda|=*=gpu",
      "nvidia-apex-proc =*=cpu",
      "pytorch =*=cuda*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cpu"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cpu_py39h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cpu*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "pytorch =*=cpu*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   },
   {
    "about": {
     "home": "https://github.com/conda-forge/nvidia-apex-feedstock",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "summary": "A meta-package to select CPU or GPU nvidia-apex build."
    },
    "build": {
     "string": "cuda"
    },
    "name": "nvidia-apex-proc",
    "test": {
     "commands": [
      "exit 0"
     ]
    },
    "version": "1.0.0"
   },
   {
    "about": {
     "dev_url": "https://github.com/NVIDIA/apex",
     "doc_url": "https://nvidia.github.io/apex/",
     "home": "https://nvidia.github.io/apex/",
     "license": "BSD-3-Clause",
     "license_family": "BSD",
     "license_file": "LICENSE",
     "summary": "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
    },
    "build": {
     "script": [
      "export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"",
      "python -m pip install . -vv"
     ],
     "string": "cuda112py39h1234567_1"
    },
    "name": "nvidia-apex",
    "requirements": {
     "build": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub"
     ],
     "host": [
      "python",
      "pytorch",
      "pytorch =*=cuda*",
      "setuptools",
      "pip"
     ],
     "run": [
      "python",
      "cxxfilt",
      "tqdm",
      "numpy",
      "PyYAML",
      "pytest"
     ],
     "run_constrained": [
      "nvidia-apex-proc =*=cuda|=*=gpu",
      "nvidia-apex-proc =*=cpu",
      "pytorch =*=cuda*"
     ]
    },
    "test": {
     "imports": [
      "apex",
      "apex.amp",
      "apex.parallel",
      "apex.optimizers",
      "apex.normalization.fused_layer_norm"
     ]
    },
    "version": "22.03"
   }
  ],
  "package": {
   "name": "nvidia-apex-split",
   "version": "22.03"
  },
  "source": {
   "sha256": "694f1ac1aaed6435b2f0c2ebc1af56b8a215a5eaa96c2565a578e8734378ff66",
   "url": "https://github.com/NVIDIA/apex/archive/refs/tags/22.03.tar.gz"
  }
 },
 "name": "nvidia-apex-split",
 "new_version": "22.03",
 "new_version_attempts": {
  "22.03": 23
 },
 "new_version_errors": {
  "22.03": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '22.03' to make sure they exist!\n\nWe also found the following errors:\n\n - recipe did not appear to change even though the bot said it should have\n"
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "nvidia-apex",
   "nvidia-apex-proc"
  ]
 },
 "pinning_version": "2022.12.27.19.59.10",
 "pre_pr_migrator_attempts": {
  "python39": 1,
  "pytorch": 1,
  "version": 2
 },
 "pre_pr_migrator_status": {
  "python39": "not solvable: master: ['linux_64_cuda_compiler_version10.0python3.9.____cpython: Encountered problems while solving.\\nProblem: nothing provides cudatoolkit 7.5* needed by pytorch-0.2.0-py27cuda7.5cudnn5.1_0\\n', 'linux_64_cuda_compiler_version10.1python3.9.____cpython: Encountered problems while solving.\\nProblem: nothing provides cudatoolkit 7.5* needed by pytorch-0.2.0-py27cuda7.5cudnn5.1_0\\n', 'linux_64_cuda_compiler_version10.2python3.9.____cpython: Encountered problems while solving.\\nProblem: nothing provides cudatoolkit 7.5* needed by pytorch-0.2.0-py27cuda7.5cudnn5.1_0\\n', 'linux_64_cuda_compiler_version11.0python3.9.____cpython: Encountered problems while solving.\\nProblem: nothing provides cudatoolkit 7.5* needed by pytorch-0.2.0-py27cuda7.5cudnn5.1_0\\n', 'linux_64_cuda_compiler_version9.2python3.9.____cpython: Encountered problems while solving.\\nProblem: nothing provides cudatoolkit 7.5* needed by pytorch-0.2.0-py27cuda7.5cudnn5.1_0\\n', 'linux_64_cuda_compiler_versionNonepython3.9.____cpython: Encountered problems while solving.\\nProblem: nothing provides cudatoolkit 7.5* needed by pytorch-0.2.0-py27cuda7.5cudnn5.1_0\\n', 'win_64_cuda_compiler_version10.0python3.9.____cpython: Encountered problems while solving.\\nProblem: package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n', 'win_64_cuda_compiler_version10.1python3.9.____cpython: Encountered problems while solving.\\nProblem: package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n', 'win_64_cuda_compiler_version10.2python3.9.____cpython: Encountered problems while solving.\\nProblem: package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n', 'win_64_cuda_compiler_version11.0python3.9.____cpython: Encountered problems while solving.\\nProblem: package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n', 'win_64_cuda_compiler_versionNonepython3.9.____cpython: Encountered problems while solving.\\nProblem: package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n']",
  "pytorch": "not solvable (<a href=\"https://github.com/regro/autotick-bot/actions/runs/1082076860\">bot CI job</a>): master: ['win_64_cuda_compiler_version10.2python3.9.____cpython: Encountered problems while solving:\\n  - package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n', 'win_64_cuda_compiler_version11.0python3.9.____cpython: Encountered problems while solving:\\n  - package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n', 'win_64_cuda_compiler_version11.1python3.9.____cpython: Encountered problems while solving:\\n  - package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n', 'win_64_cuda_compiler_version11.2python3.9.____cpython: Encountered problems while solving:\\n  - package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n', 'win_64_cuda_compiler_versionNonepython3.9.____cpython: Encountered problems while solving:\\n  - package pytorch-1.0.1-cpu_py36h39a92a0_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\\n']",
  "version": "bot error (<a href=\"https://github.com/regro/autotick-bot/actions/runs/3622111625\">bot CI job</a>): main: Traceback (most recent call last):\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/auto_tick.py\", line 1166, in _run_migrator\n    migrator_uid, pr_json = run(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/auto_tick.py\", line 211, in run\n    feedstock_dir, repo = get_repo(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/git_utils.py\", line 314, in get_repo\n    if fetch_repo(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/git_utils.py\", line 214, in fetch_repo\n    _run_git_cmd(f\"git fetch --all {quiet}\")\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/git_utils.py\", line 199, in _run_git_cmd\n    return subprocess.run(cmd, shell=True, check=True)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/subprocess.py\", line 528, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command 'git fetch --all --quiet' returned non-zero exit status 1.\n"
 },
 "raw_meta_yaml": "{% set version = \"22.03\" %}\n{% set proc_version = \"1.0.0\" %}\n\n# see github.com/conda-forge/conda-forge.github.io/issues/1059 for naming discussion\n{% set proc_type = \"cuda\" if cuda_compiler_version != \"None\" else \"cpu\" %}\n\npackage:\n  name: nvidia-apex-split\n  version: {{ version }}\n\nsource:\n  url: https://github.com/NVIDIA/apex/archive/refs/tags/{{ version }}.tar.gz\n  sha256: 694f1ac1aaed6435b2f0c2ebc1af56b8a215a5eaa96c2565a578e8734378ff66\n\nbuild:\n  number: 1\n  skip: True  # [osx or win]\n  # as of pytorch 1.13, conda-forge only builds for CUDA 11.2+, see\n  # https://github.com/conda-forge/conda-forge-pinning-feedstock/issues/3491\n  skip: true  # [cuda_compiler_version in (\"10.2\", \"11.0\", \"11.1\")]\n\noutputs:\n  - name: nvidia-apex-proc\n    version: {{ proc_version }}\n    build:\n      string: {{ proc_type }}\n    test:\n      commands:\n        - exit 0\n    about:\n      home: https://github.com/conda-forge/nvidia-apex-feedstock\n      license: BSD-3-Clause\n      license_family: BSD\n      summary: A meta-package to select CPU or GPU nvidia-apex build.\n\n  - name: nvidia-apex\n    version: {{ version }}\n    build:\n      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                # [cuda_compiler_version == \"None\"]\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n      script:\n        - export TORCH_CUDA_ARCH_LIST=\"3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6\"\n        - python -m pip install . -vv\n    requirements:\n      build:\n        - {{ compiler('c') }}\n        - {{ compiler('cxx') }}\n        - {{ compiler('cuda') }}  # [linux64 and cuda_compiler_version != \"None\"]\n      host:\n        - python\n        - pytorch\n        - pytorch =*={{ proc_type }}*\n        - setuptools\n        - pip\n      run:\n        - python\n        - cxxfilt  # [linux]\n        - tqdm\n        - numpy\n        - PyYAML\n        - pytest\n      run_constrained:\n        # old constraint used \"gpu\"\n        - nvidia-apex-proc =*=cuda|=*=gpu  # [cuda_compiler_version != \"None\"]\n        - nvidia-apex-proc =*=cpu          # [cuda_compiler_version != \"None\"]\n        - pytorch =*={{ proc_type }}*\n    test:\n      imports:\n        - apex\n        - apex.amp\n        - apex.parallel\n        - apex.optimizers\n        - apex.normalization.fused_layer_norm\n    about:\n      home: \"https://nvidia.github.io/apex/\"\n      license: BSD-3-Clause\n      license_family: BSD\n      license_file: LICENSE\n      summary: \"a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training.\"\n      doc_url: \"https://nvidia.github.io/apex/\"\n      dev_url: \"https://github.com/NVIDIA/apex\"\n\nabout:\n  home: \"https://nvidia.github.io/apex/\"\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file: LICENSE\n  summary: \"a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training.\"\n  doc_url: \"https://nvidia.github.io/apex/\"\n  dev_url: \"https://github.com/NVIDIA/apex\"\n\nextra:\n  recipe-maintainers:\n    - h-vetinari\n    - oblute\n    - benhuff\n    - jakirkham\n    - rluria14\n  feedstock-name: nvidia-apex\n",
 "req": {
  "__set__": true,
  "elements": [
   "c_compiler_stub",
   "cuda_compiler_stub",
   "cxx_compiler_stub",
   "cxxfilt",
   "numpy",
   "pip",
   "pytest",
   "python",
   "pytorch",
   "pyyaml",
   "setuptools",
   "tqdm"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cuda_compiler_stub",
    "cxx_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "pip",
    "python",
    "pytorch",
    "setuptools"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "cxxfilt",
    "numpy",
    "pytest",
    "python",
    "pyyaml",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "smithy_version": "3.22.1",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cuda_compiler_stub",
    "cxx_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "pytorch",
    "pytorch =*=cpu*",
    "pytorch =*=cuda*",
    "setuptools"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "PyYAML",
    "cxxfilt",
    "numpy",
    "pytest",
    "python",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": "https://github.com/NVIDIA/apex/archive/refs/tags/22.03.tar.gz",
 "version": "22.03"
}