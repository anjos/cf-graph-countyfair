{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/805876497.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.3.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/815999987.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.3.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/833052355.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/835531406.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "syntok",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "Syntok is the successor of an earlier, very similar tool, segtok, but has evolved\nsignificantly in terms of providing better segmentation and tokenization performance\nand throughput (syntok can segment documents at a rate of about 100k tokens per\nsecond without problems). For example, if a sentence terminal marker is not\nfollowed by a spacing character, segtok is unable to detect that as a terminal\nmarker, while syntok has no problem segmenting that case (as it uses tokenization\nfirst, and does segmentation afterwards).\n",
   "home": "https://github.com/fnl/syntok",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": "LICENSE",
   "summary": "sentence segmentation and word tokenization toolkit"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "BastianZim"
   ]
  },
  "package": {
   "name": "syntok",
   "version": "1.4.2"
  },
  "requirements": {
   "host": [
    "pip",
    "poetry-core >=1.0.0",
    "python >=3.6"
   ],
   "run": [
    "python >=3.6",
    "regex >2016"
   ]
  },
  "source": {
   "sha256": "7ee9016139f04c7424e6c5771a46fd5622991cff54c781e9e31270214d3276fe",
   "url": "https://pypi.io/packages/source/s/syntok/syntok-1.4.2.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "syntok"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry-core",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python",
    "regex"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "description": "Syntok is the successor of an earlier, very similar tool, segtok, but has evolved\nsignificantly in terms of providing better segmentation and tokenization performance\nand throughput (syntok can segment documents at a rate of about 100k tokens per\nsecond without problems). For example, if a sentence terminal marker is not\nfollowed by a spacing character, segtok is unable to detect that as a terminal\nmarker, while syntok has no problem segmenting that case (as it uses tokenization\nfirst, and does segmentation afterwards).\n",
   "home": "https://github.com/fnl/syntok",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": "LICENSE",
   "summary": "sentence segmentation and word tokenization toolkit"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "BastianZim"
   ]
  },
  "package": {
   "name": "syntok",
   "version": "1.4.2"
  },
  "requirements": {
   "host": [
    "pip",
    "poetry-core >=1.0.0",
    "python >=3.6"
   ],
   "run": [
    "python >=3.6",
    "regex >2016"
   ]
  },
  "source": {
   "sha256": "7ee9016139f04c7424e6c5771a46fd5622991cff54c781e9e31270214d3276fe",
   "url": "https://pypi.io/packages/source/s/syntok/syntok-1.4.2.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "syntok"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "name": "syntok",
 "new_version": "1.4.3",
 "new_version_attempts": {
  "1.3.2": 1,
  "1.3.3": 1,
  "1.4.1": 1,
  "1.4.2": 1,
  "1.4.3": 29
 },
 "new_version_errors": {
  "1.4.3": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '1.4.3' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz'\n"
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "syntok"
  ]
 },
 "pinning_version": "2022.01.29.15.10.18",
 "raw_meta_yaml": "{% set name = \"syntok\" %}\n{% set version = \"1.4.2\" %}\n\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 7ee9016139f04c7424e6c5771a46fd5622991cff54c781e9e31270214d3276fe\n\nbuild:\n  number: 0\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - poetry-core >=1.0.0\n    - python >=3.6\n  run:\n    - python >=3.6\n    - regex >2016\n\ntest:\n  imports:\n    - syntok\n  commands:\n    - pip check\n  requires:\n    - pip\n\nabout:\n  home: https://github.com/fnl/syntok\n  summary: sentence segmentation and word tokenization toolkit\n  description: |\n    Syntok is the successor of an earlier, very similar tool, segtok, but has evolved\n    significantly in terms of providing better segmentation and tokenization performance\n    and throughput (syntok can segment documents at a rate of about 100k tokens per\n    second without problems). For example, if a sentence terminal marker is not\n    followed by a spacing character, segtok is unable to detect that as a terminal\n    marker, while syntok has no problem segmenting that case (as it uses tokenization\n    first, and does segmentation afterwards).\n  license: MIT\n  license_family: MIT\n  license_file: LICENSE\n\nextra:\n  recipe-maintainers:\n    - BastianZim\n",
 "req": {
  "__set__": true,
  "elements": [
   "pip",
   "poetry-core",
   "python",
   "regex"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry-core",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python",
    "regex"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "smithy_version": "3.16.2",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry-core >=1.0.0",
    "python >=3.6"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python >=3.6",
    "regex >2016"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/s/syntok/syntok-1.4.2.tar.gz",
 "version": "1.4.2"
}