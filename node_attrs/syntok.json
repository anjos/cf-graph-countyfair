{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/805876497.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.3.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/815999987.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.3.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/833052355.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "syntok",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "Syntok is the successor of an earlier, very similar tool, segtok, but has evolved\nsignificantly in terms of providing better segmentation and tokenization performance\nand throughput (syntok can segment documents at a rate of about 100k tokens per\nsecond without problems). For example, if a sentence terminal marker is not\nfollowed by a spacing character, segtok is unable to detect that as a terminal\nmarker, while syntok has no problem segmenting that case (as it uses tokenization\nfirst, and does segmentation afterwards).\n",
   "home": "https://github.com/fnl/syntok",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": "LICENSE",
   "summary": "sentence segmentation and word tokenization toolkit"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "BastianZim"
   ]
  },
  "package": {
   "name": "syntok",
   "version": "1.4.1"
  },
  "requirements": {
   "host": [
    "pip",
    "poetry-core >=1.0.0",
    "python >=3.6"
   ],
   "run": [
    "python >=3.6",
    "regex >2016"
   ]
  },
  "source": {
   "sha256": "7d69b421137b638bac166eb88c6a2e7d0cdf42ab06f3e33e3ed6e4306f4bc9b5",
   "url": "https://pypi.io/packages/source/s/syntok/syntok-1.4.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "syntok"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry-core",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python",
    "regex"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "description": "Syntok is the successor of an earlier, very similar tool, segtok, but has evolved\nsignificantly in terms of providing better segmentation and tokenization performance\nand throughput (syntok can segment documents at a rate of about 100k tokens per\nsecond without problems). For example, if a sentence terminal marker is not\nfollowed by a spacing character, segtok is unable to detect that as a terminal\nmarker, while syntok has no problem segmenting that case (as it uses tokenization\nfirst, and does segmentation afterwards).\n",
   "home": "https://github.com/fnl/syntok",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": "LICENSE",
   "summary": "sentence segmentation and word tokenization toolkit"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "BastianZim"
   ]
  },
  "package": {
   "name": "syntok",
   "version": "1.4.1"
  },
  "requirements": {
   "host": [
    "pip",
    "poetry-core >=1.0.0",
    "python >=3.6"
   ],
   "run": [
    "python >=3.6",
    "regex >2016"
   ]
  },
  "source": {
   "sha256": "7d69b421137b638bac166eb88c6a2e7d0cdf42ab06f3e33e3ed6e4306f4bc9b5",
   "url": "https://pypi.io/packages/source/s/syntok/syntok-1.4.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "syntok"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "name": "syntok",
 "new_version": "1.4.1",
 "new_version_attempts": {
  "1.3.2": 1,
  "1.3.3": 1,
  "1.4.1": 1
 },
 "new_version_errors": {},
 "outputs_names": {
  "__set__": true,
  "elements": [
   "syntok"
  ]
 },
 "pinning_version": "2022.01.26.20.27.23",
 "raw_meta_yaml": "{% set name = \"syntok\" %}\n{% set version = \"1.4.1\" %}\n\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 7d69b421137b638bac166eb88c6a2e7d0cdf42ab06f3e33e3ed6e4306f4bc9b5\n\nbuild:\n  number: 0\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - poetry-core >=1.0.0\n    - python >=3.6\n  run:\n    - python >=3.6\n    - regex >2016\n\ntest:\n  imports:\n    - syntok\n  commands:\n    - pip check\n  requires:\n    - pip\n\nabout:\n  home: https://github.com/fnl/syntok\n  summary: sentence segmentation and word tokenization toolkit\n  description: |\n    Syntok is the successor of an earlier, very similar tool, segtok, but has evolved\n    significantly in terms of providing better segmentation and tokenization performance\n    and throughput (syntok can segment documents at a rate of about 100k tokens per\n    second without problems). For example, if a sentence terminal marker is not\n    followed by a spacing character, segtok is unable to detect that as a terminal\n    marker, while syntok has no problem segmenting that case (as it uses tokenization\n    first, and does segmentation afterwards).\n  license: MIT\n  license_family: MIT\n  license_file: LICENSE\n\nextra:\n  recipe-maintainers:\n    - BastianZim\n",
 "req": {
  "__set__": true,
  "elements": [
   "pip",
   "poetry-core",
   "python",
   "regex"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry-core",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python",
    "regex"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "smithy_version": "3.16.2",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry-core >=1.0.0",
    "python >=3.6"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python >=3.6",
    "regex >2016"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/s/syntok/syntok-1.4.1.tar.gz",
 "version": "1.4.1"
}