{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/346697044.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.6.5"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/346701272.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python38"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/350165079.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.6.6"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/361669587.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.6.7"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/362397361.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.6.7.post0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/368173883.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.6.8"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/368855006.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.6.9"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/374621035.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/378043592.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/380615278.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/384033167.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/415621913.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.11.post0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/417003351.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.12"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/418301330.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.13"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/421666303.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.14"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/424858774.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.15"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/428202132.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.7.16"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/434885912.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/436062515.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/437334641.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.4"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/440355828.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.5"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/443773623.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.6"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/447130087.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.7"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/450490437.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.8"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/456430131.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.9"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/459711016.json"
   },
   "data": {
    "bot_rerun": 1596834980.1606555,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.8.10"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/464839020.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.9.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/464907470.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.9.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/465033583.json"
   },
   "data": {
    "bot_rerun": 1596924873.1429312,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/465081108.json"
   },
   "data": {
    "bot_rerun": 1600812355.7025394,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/491856119.json"
   },
   "data": {
    "bot_rerun": 1603216857.544536,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/507037152.json"
   },
   "data": {
    "bot_rerun": 1605057079.3813057,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/514578389.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 2,
    "migrator_version": 0,
    "name": "python39"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/519026890.json"
   },
   "data": {
    "bot_rerun": 1605907611.5716593,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/524970527.json"
   },
   "data": {
    "bot_rerun": 1606001697.1463606,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/525205830.json"
   },
   "data": {
    "bot_rerun": 1607048846.870822,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/532253402.json"
   },
   "data": {
    "bot_rerun": 1612505422.5796146,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/568154396.json"
   },
   "data": {
    "bot_rerun": 1612538406.0401397,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/568474138.json"
   },
   "data": {
    "bot_rerun": 1612555759.4158142,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/568623513.json"
   },
   "data": {
    "bot_rerun": 1612578212.9027662,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/568712526.json"
   },
   "data": {
    "bot_rerun": 1613925683.913791,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/577149898.json"
   },
   "data": {
    "bot_rerun": 1614458585.2461307,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/581406434.json"
   },
   "data": {
    "bot_rerun": 1614925975.161597,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/585366301.json"
   },
   "data": {
    "bot_rerun": 1616374217.8690183,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/597600728.json"
   },
   "data": {
    "bot_rerun": 1616504787.151411,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/598469764.json"
   },
   "data": {
    "bot_rerun": 1616518281.9817405,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/598853340.json"
   },
   "data": {
    "bot_rerun": 1616773755.256283,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/601287950.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/601737189.json"
   },
   "data": {
    "bot_rerun": 1617466807.5102332,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/607741875.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/608410989.json"
   },
   "data": {
    "bot_rerun": 1618087252.2448058,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/612064102.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.4"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/612962437.json"
   },
   "data": {
    "bot_rerun": 1618885463.6389015,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/618586102.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.5"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/618965468.json"
   },
   "data": {
    "bot_rerun": 1619386577.074476,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/622304129.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.6"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/622846594.json"
   },
   "data": {
    "bot_rerun": 1619911385.070698,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/628052866.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.7"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/f4eedbaf-6f90-4bd6-ac2e-77309fde5428.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/632287142.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.11.8"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/691468751.json"
   },
   "data": {
    "bot_rerun": 1633649933.067933,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy37"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/696304139.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/699854152.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.4"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/705418983.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.5"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/711954537.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.6"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/716481323.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.7"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/721069219.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.8"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/726486645.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.9"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/731139440.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.10"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/736647309.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.11"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/742542769.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.12"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/747178125.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.13"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/754475524.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.14"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/755590151.json"
   },
   "data": {
    "bot_rerun": 1638571598.1470394,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "pypy37"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/759016851.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.12.15"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/763837091.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/766142310.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/768952742.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/772955929.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/773939676.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.4"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/779069230.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.5"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/781471185.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.6"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/783388626.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.7"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/784326233.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.8"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/791431296.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.9"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/793295489.json"
   },
   "data": {
    "bot_rerun": 1638549381.928876,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python310"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/794223147.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.10"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/794834879.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "MigrationYaml",
    "migrator_object_version": 1,
    "migrator_version": 0,
    "name": "python310"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/799468812.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.11"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/805082783.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.12"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/816053238.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.13"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/821835826.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "0.13.14"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "dagster",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "Dagster is a system for building modern data applications. Combining an elegant programming model and beautiful tools, Dagster allows infrastructure engineers, data engineers, and data scientists to seamlessly collaborate to process and produce the trusted, reliable data needed in today's world.",
   "doc_url": "https://dagster.readthedocs.io",
   "home": "https://github.com/dagster-io",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "dagster/LICENSE",
   "summary": "The data orchestration platform built for productivity."
  },
  "build": {
   "number": "0"
  },
  "extra": {
   "feedstock-name": "dagster",
   "recipe-maintainers": [
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner"
   ]
  },
  "outputs": [
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   }
  ],
  "package": {
   "name": "dagster-meta",
   "version": "0.13.13"
  },
  "requirements": {
   "host": [
    "python",
    "python",
    "python",
    "python"
   ],
   "run": [
    "python",
    "python",
    "python",
    "python"
   ]
  },
  "source": [
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\""
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "alembic",
    "click",
    "coloredlogs",
    "croniter",
    "docstring_parser",
    "grpcio",
    "grpcio-health-checking",
    "jinja2",
    "packaging",
    "pendulum",
    "protobuf",
    "python",
    "python-dateutil",
    "pytz",
    "pyyaml",
    "rx",
    "setuptools",
    "sqlalchemy",
    "tabulate",
    "toposort",
    "tqdm",
    "typing-compat",
    "tzlocal",
    "watchdog"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "description": "Dagster is a system for building modern data applications. Combining an elegant programming model and beautiful tools, Dagster allows infrastructure engineers, data engineers, and data scientists to seamlessly collaborate to process and produce the trusted, reliable data needed in today's world.",
   "doc_url": "https://dagster.readthedocs.io",
   "home": "https://github.com/dagster-io",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "dagster/LICENSE",
   "summary": "The data orchestration platform built for productivity."
  },
  "build": {
   "number": "0"
  },
  "extra": {
   "feedstock-name": "dagster",
   "recipe-maintainers": [
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner"
   ]
  },
  "outputs": [
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "psutil >=1.0",
      "python",
      "python-dateutil",
      "pytz",
      "pywin32 !=226",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "psutil >=1.0",
      "python",
      "python-dateutil",
      "pytz",
      "pywin32 !=226",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "psutil >=1.0",
      "python",
      "python-dateutil",
      "pytz",
      "pywin32 !=226",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "psutil >=1.0",
      "python",
      "python-dateutil",
      "pytz",
      "pywin32 !=226",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   }
  ],
  "package": {
   "name": "dagster-meta",
   "version": "0.13.13"
  },
  "requirements": {
   "host": [
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python"
   ],
   "run": [
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python",
    "python"
   ]
  },
  "source": [
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\""
   ]
  }
 },
 "name": "dagster-meta",
 "new_version": "0.13.14",
 "new_version_attempts": {
  "0.10.0": 11,
  "0.10.1": 8,
  "0.10.2": 15,
  "0.10.3": 3,
  "0.10.4": 3,
  "0.10.5": 11,
  "0.10.6": 9,
  "0.10.7": 6,
  "0.10.8": 1,
  "0.10.9": 14,
  "0.11.0": 8,
  "0.11.1": 2,
  "0.11.10": 5,
  "0.11.11": 8,
  "0.11.12": 8,
  "0.11.13": 7,
  "0.11.14": 13,
  "0.11.15": 1,
  "0.11.16": 9,
  "0.11.2": 1,
  "0.11.3": 1,
  "0.11.4": 1,
  "0.11.5": 1,
  "0.11.6": 1,
  "0.11.7": 1,
  "0.11.8": 1,
  "0.11.9": 9,
  "0.12.0": 5,
  "0.12.1": 22,
  "0.12.10": 1,
  "0.12.11": 1,
  "0.12.12": 1,
  "0.12.13": 1,
  "0.12.14": 3,
  "0.12.15": 3,
  "0.12.2": 3,
  "0.12.3": 4,
  "0.12.4": 1,
  "0.12.5": 1,
  "0.12.6": 1,
  "0.12.7": 2,
  "0.12.8": 1,
  "0.12.9": 1,
  "0.13.0": 2,
  "0.13.1": 3,
  "0.13.10": 1,
  "0.13.11": 1,
  "0.13.12": 2,
  "0.13.13": 1,
  "0.13.14": 1,
  "0.13.2": 1,
  "0.13.3": 2,
  "0.13.4": 1,
  "0.13.5": 1,
  "0.13.6": 3,
  "0.13.7": 1,
  "0.13.8": 2,
  "0.13.9": 2,
  "0.7.10": 22,
  "0.7.11": 13,
  "0.7.11.post0": 3,
  "0.7.12": 1,
  "0.7.13": 1,
  "0.7.14": 1,
  "0.7.15": 1,
  "0.7.16": 1,
  "0.7.6": 248,
  "0.7.7": 114,
  "0.7.8": 184,
  "0.7.9": 61,
  "0.8.0": 4,
  "0.8.1": 1,
  "0.8.10": 1,
  "0.8.2": 1,
  "0.8.3": 1,
  "0.8.4": 1,
  "0.8.5": 1,
  "0.8.6": 1,
  "0.8.7": 1,
  "0.8.8": 1,
  "0.8.9": 11,
  "0.9.0": 1,
  "0.9.1": 1,
  "0.9.10": 1,
  "0.9.11": 18,
  "0.9.12": 4,
  "0.9.13": 7,
  "0.9.14": 13,
  "0.9.15": 16,
  "0.9.16": 11,
  "0.9.17": 4,
  "0.9.19": 3,
  "0.9.2": 53,
  "0.9.20": 20,
  "0.9.21": 2,
  "0.9.22": 3,
  "0.9.22.post0": 306,
  "0.9.3": 54,
  "0.9.4": 79,
  "0.9.5": 3,
  "0.9.6": 14,
  "0.9.7": 44,
  "0.9.8": 21,
  "0.9.9": 8
 },
 "new_version_errors": {
  "0.10.0": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 934, column 5:\n      - name: dagster-k8s\n        ^ (line: 934)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 964, column 5:\n        about:\n        ^ (line: 964)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.10.1": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 934, column 5:\n      - name: dagster-k8s\n        ^ (line: 934)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 964, column 5:\n        about:\n        ^ (line: 964)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.10.2": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 934, column 5:\n      - name: dagster-k8s\n        ^ (line: 934)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 964, column 5:\n        about:\n        ^ (line: 964)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.10.3": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 934, column 5:\n      - name: dagster-k8s\n        ^ (line: 934)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 964, column 5:\n        about:\n        ^ (line: 964)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.10.4": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 925, column 5:\n      - name: dagster-k8s\n        ^ (line: 925)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 956, column 5:\n        about:\n        ^ (line: 956)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.10.5": "We found a problem parsing the recipe for version '0.10.5': \n\nDuplicateKeyError('while constructing a mapping', <ruamel.yaml.error.StringMark object at 0x7f886e2be0b0>, 'found duplicate key \"license_file\" with value \"dagster/LICENSE\" (original value: \"dagster-docker/LICENSE\")', <ruamel.yaml.error.StringMark object at 0x7f886e2bea50>, '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/main.py\", line 343, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 113, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 123, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1555, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1317, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1470, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.10.6": "We found a problem parsing the recipe for version '0.10.6': \n\nDuplicateKeyError('while constructing a mapping', <ruamel.yaml.error.StringMark object at 0x7efbe77a27b0>, 'found duplicate key \"license_file\" with value \"dagster/LICENSE\" (original value: \"dagster-docker/LICENSE\")', <ruamel.yaml.error.StringMark object at 0x7efbe7798190>, '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/main.py\", line 343, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 113, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 123, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1555, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1317, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1470, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.10.7": "We found a problem parsing the recipe for version '0.10.7': \n\nDuplicateKeyError('while constructing a mapping', <ruamel.yaml.error.StringMark object at 0x7fb8d6744270>, 'found duplicate key \"license_file\" with value \"dagster/LICENSE\" (original value: \"dagster-docker/LICENSE\")', <ruamel.yaml.error.StringMark object at 0x7fb8d6744c10>, '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/main.py\", line 343, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 113, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 123, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1555, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1317, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1470, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.10.8": "We found a problem parsing the recipe for version '0.10.8': \n\nDuplicateKeyError('while constructing a mapping', <ruamel.yaml.error.StringMark object at 0x7f164456f970>, 'found duplicate key \"license_file\" with value \"dagster/LICENSE\" (original value: \"dagster-docker/LICENSE\")', <ruamel.yaml.error.StringMark object at 0x7f16445c0350>, '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/main.py\", line 343, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 113, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 123, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1555, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1317, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 1470, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.8/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.10.9": "We found a problem parsing the recipe for version '0.10.9': \n\nDuplicateKeyError('while constructing a mapping', <ruamel.yaml.error.StringMark object at 0x7f93afb6ccf0>, 'found duplicate key \"license_file\" with value \"dagster/LICENSE\" (original value: \"dagster-docker/LICENSE\")', <ruamel.yaml.error.StringMark object at 0x7f93afb6e6d0>, '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 343, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 113, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 123, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1555, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1317, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1470, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.0": "We found a problem parsing the recipe for version '0.11.0': \n\nDuplicateKeyError('while constructing a mapping', <ruamel.yaml.error.StringMark object at 0x7f9163164a50>, 'found duplicate key \"license_file\" with value \"dagster/LICENSE\" (original value: \"dagster-docker/LICENSE\")', <ruamel.yaml.error.StringMark object at 0x7f91b14b6430>, '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 343, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 113, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 123, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1555, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1317, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1469, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 146, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 188, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1563, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1470, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.10": "We found a problem parsing the recipe for version '0.11.10': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 579, column 7:\n          requires:\n          ^ (line: 579), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 581, column 7:\n          requires:\n          ^ (line: 581), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 421, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 111, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 121, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1533, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1447, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 144, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 186, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1525, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1297, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 144, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 186, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1533, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1447, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 144, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 186, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1533, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1448, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 284, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.11": "We found a problem parsing the recipe for version '0.11.11': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 579, column 7:\n          requires:\n          ^ (line: 579), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 581, column 7:\n          requires:\n          ^ (line: 581), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.12": "We found a problem parsing the recipe for version '0.11.12': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 579, column 7:\n          requires:\n          ^ (line: 579), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 581, column 7:\n          requires:\n          ^ (line: 581), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.13": "We found a problem parsing the recipe for version '0.11.13': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 579, column 7:\n          requires:\n          ^ (line: 579), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 581, column 7:\n          requires:\n          ^ (line: 581), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.14": "We found a problem parsing the recipe for version '0.11.14': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 579, column 7:\n          requires:\n          ^ (line: 579), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 581, column 7:\n          requires:\n          ^ (line: 581), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 502, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.15": "We found a problem parsing the recipe for version '0.11.15': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 579, column 7:\n          requires:\n          ^ (line: 579), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 581, column 7:\n          requires:\n          ^ (line: 581), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 502, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.16": "We found a problem parsing the recipe for version '0.11.16': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 580, column 7:\n          requires:\n          ^ (line: 580), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 582, column 7:\n          requires:\n          ^ (line: 582), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 502, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.11.9": "We found a problem parsing the recipe for version '0.11.9': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 579, column 7:\n          requires:\n          ^ (line: 579), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 581, column 7:\n          requires:\n          ^ (line: 581), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 472, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 421, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 111, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 121, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1533, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1447, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 144, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 186, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1525, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1297, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 144, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 186, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1533, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1447, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 144, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 186, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1533, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1448, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 284, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.12.0": "We found a problem parsing the recipe for version '0.12.0': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 580, column 7:\n          requires:\n          ^ (line: 580), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 582, column 7:\n          requires:\n          ^ (line: 582), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 502, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.12.1": "We found a problem parsing the recipe for version '0.12.1': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 580, column 7:\n          requires:\n          ^ (line: 580), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 582, column 7:\n          requires:\n          ^ (line: 582), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 502, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.12.2": "We found a problem parsing the recipe for version '0.12.2': \n\nDuplicateKeyError('while constructing a mapping',   in \"<unicode string>\", line 580, column 7:\n          requires:\n          ^ (line: 580), 'found duplicate key \"requires\" with value \"[\\'python >=3.6\\']\" (original value: \"[\\'pip\\']\")',   in \"<unicode string>\", line 582, column 7:\n          requires:\n          ^ (line: 582), '\\n                    To suppress this check see:\\n                        http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\\n                    ', '                    Duplicate keys will become an error in future releases, and are errors\\n                    by default when using the new API.\\n                    ')\n\ntraceback:\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/migrators/version.py\", line 502, in migrate\n    cmeta = CondaMetaYAML(fp.read())\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/recipe_parser/_parser.py\", line 455, in __init__\n    self.meta = self._parser.load(\"\".join(lines))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/main.py\", line 434, in load\n    return constructor.get_single_data()\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 122, in get_single_data\n    return self.construct_document(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 132, in construct_document\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1609, in construct_yaml_seq\n    data.extend(self.construct_rt_sequence(node, data))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1341, in construct_rt_sequence\n    ret_val.append(self.construct_object(child, deep=deep))\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1500, in construct_mapping\n    value = self.construct_object(value_node, deep=deep)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 155, in construct_object\n    data = self.construct_non_recursive_object(node)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 197, in construct_non_recursive_object\n    for _dummy in generator:\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1617, in construct_yaml_map\n    self.construct_mapping(node, data, deep=True)\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 1501, in construct_mapping\n    if self.check_mapping_key(node, key_node, maptyp, key, value):\n  File \"/usr/share/miniconda/envs/run_env/lib/python3.9/site-packages/ruamel/yaml/constructor.py\", line 295, in check_mapping_key\n    raise DuplicateKeyError(*args)\n",
  "0.12.3": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.12.3' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-datadog/dagster-datadog-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-github/dagster-github-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ssh/dagster-ssh-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-twilio/dagster-twilio-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-mlflow/dagster-mlflow-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-pandas/dagster-pandas-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagstermill/dagstermill-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-spark/dagster-spark-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-dask/dagster-dask-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-celery/dagster-celery-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-celery-docker/dagster-celery-docker-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-celery-k8s/dagster-celery-k8s-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-docker/dagster-docker-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-dbt/dagster-dbt-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-pagerduty/dagster-pagerduty-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-gcp/dagster-gcp-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-graphql/dagster-graphql-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagit/dagit-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-mysql/dagster-mysql-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-pyspark/dagster-pyspark-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-slack/dagster-slack-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-prometheus/dagster-prometheus-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-snowflake/dagster-snowflake-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-papertrail/dagster-papertrail-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-airflow/dagster-airflow-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-postgres/dagster-postgres-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-k8s/dagster-k8s-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-shell/dagster-shell-{{ version }}.tar.gz'\n",
  "0.7.10": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.7.10' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz'\n",
  "0.7.11": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.7.11' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz'\n",
  "0.7.11.post0": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.7.11.post0' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz'\n",
  "0.7.6": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.7.6' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz'\n",
  "0.7.7": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.7.7' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz'\n",
  "0.7.8": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.7.8' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz'\n",
  "0.7.9": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.7.9' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz'\n",
  "0.8.0": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.8.0' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-dbt/dagster-dbt-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-bash/dagster-bash-{{ version }}.tar.gz'\n",
  "0.8.1": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.8.1' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-dbt/dagster-dbt-{{ version }}.tar.gz'\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-bash/dagster-bash-{{ version }}.tar.gz'\n",
  "0.8.9": "The recipe did not change in the version migration, a URL did not hash, or there is jinja2 syntax the bot cannot handle!\n\nPlease check the URLs in your recipe with version '0.8.9' to make sure they exist!\n\nWe also found the following errors:\n\n - could not hash URL template 'https://pypi.io/packages/source/d/dagster-prometheus/dagster-prometheus-{{ version }}.tar.gz'\n",
  "0.9.10": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 896, column 5:\n      - name: dagster-k8s\n        ^ (line: 896)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 926, column 5:\n        about:\n        ^ (line: 926)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.11": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 896, column 5:\n      - name: dagster-k8s\n        ^ (line: 896)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 926, column 5:\n        about:\n        ^ (line: 926)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.12": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 896, column 5:\n      - name: dagster-k8s\n        ^ (line: 896)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 926, column 5:\n        about:\n        ^ (line: 926)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.13": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 896, column 5:\n      - name: dagster-k8s\n        ^ (line: 896)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 926, column 5:\n        about:\n        ^ (line: 926)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.14": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 899, column 5:\n      - name: dagster-k8s\n        ^ (line: 899)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 929, column 5:\n        about:\n        ^ (line: 929)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.15": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 899, column 5:\n      - name: dagster-k8s\n        ^ (line: 899)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 929, column 5:\n        about:\n        ^ (line: 929)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.16": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 899, column 5:\n      - name: dagster-k8s\n        ^ (line: 899)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 929, column 5:\n        about:\n        ^ (line: 929)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.17": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 933, column 5:\n      - name: dagster-k8s\n        ^ (line: 933)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 963, column 5:\n        about:\n        ^ (line: 963)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.19": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 934, column 5:\n      - name: dagster-k8s\n        ^ (line: 934)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 964, column 5:\n        about:\n        ^ (line: 964)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.2": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 848, column 5:\n      - name: dagster-k8s\n        ^ (line: 848)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 878, column 5:\n        about:\n        ^ (line: 878)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.20": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 934, column 5:\n      - name: dagster-k8s\n        ^ (line: 934)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 964, column 5:\n        about:\n        ^ (line: 964)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.21": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 936, column 5:\n      - name: dagster-k8s\n        ^ (line: 936)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 966, column 5:\n        about:\n        ^ (line: 966)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.22": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 934, column 5:\n      - name: dagster-k8s\n        ^ (line: 934)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 964, column 5:\n        about:\n        ^ (line: 964)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.22.post0": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 934, column 5:\n      - name: dagster-k8s\n        ^ (line: 934)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 964, column 5:\n        about:\n        ^ (line: 964)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.3": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 849, column 5:\n      - name: dagster-k8s\n        ^ (line: 849)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 879, column 5:\n        about:\n        ^ (line: 879)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.4": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 849, column 5:\n      - name: dagster-k8s\n        ^ (line: 849)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 879, column 5:\n        about:\n        ^ (line: 879)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.5": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 886, column 5:\n      - name: dagster-k8s\n        ^ (line: 886)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 916, column 5:\n        about:\n        ^ (line: 916)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.6": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 886, column 5:\n      - name: dagster-k8s\n        ^ (line: 886)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 916, column 5:\n        about:\n        ^ (line: 916)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.7": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 886, column 5:\n      - name: dagster-k8s\n        ^ (line: 886)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 916, column 5:\n        about:\n        ^ (line: 916)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.8": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 886, column 5:\n      - name: dagster-k8s\n        ^ (line: 886)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 916, column 5:\n        about:\n        ^ (line: 916)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n",
  "0.9.9": "We found a problem parsing the recipe: \n\nwhile constructing a mapping\n  in \"<unicode string>\", line 895, column 5:\n      - name: dagster-k8s\n        ^ (line: 895)\nfound duplicate key \"about\" with value \"ordereddict([('home', 'https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster/LICENSE'), ('summary', 'A Dagster integration for celery-k8s-executor')])\" (original value: \"ordereddict([('home', 'https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s'), ('license', 'Apache-2.0'), ('license_family', 'APACHE'), ('license_file', 'dagster-github/LICENSE'), ('summary', 'A Dagster integration for k8s')])\")\n  in \"<unicode string>\", line 925, column 5:\n        about:\n        ^ (line: 925)\n\nTo suppress this check see:\n    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n\nDuplicate keys will become an error in future releases, and are errors\nby default when using the new API.\n"
 },
 "osx_64_meta_yaml": {
  "about": {
   "description": "Dagster is a system for building modern data applications. Combining an elegant programming model and beautiful tools, Dagster allows infrastructure engineers, data engineers, and data scientists to seamlessly collaborate to process and produce the trusted, reliable data needed in today's world.",
   "doc_url": "https://dagster.readthedocs.io",
   "home": "https://github.com/dagster-io",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "dagster/LICENSE",
   "summary": "The data orchestration platform built for productivity."
  },
  "build": {
   "number": "0"
  },
  "extra": {
   "feedstock-name": "dagster",
   "recipe-maintainers": [
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner"
   ]
  },
  "outputs": [
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "python",
      "python-dateutil",
      "pytz",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   }
  ],
  "package": {
   "name": "dagster-meta",
   "version": "0.13.13"
  },
  "requirements": {
   "host": [
    "python",
    "python",
    "python",
    "python"
   ],
   "run": [
    "python",
    "python",
    "python",
    "python"
   ]
  },
  "source": [
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\""
   ]
  }
 },
 "osx_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "alembic",
    "click",
    "coloredlogs",
    "croniter",
    "docstring_parser",
    "grpcio",
    "grpcio-health-checking",
    "jinja2",
    "packaging",
    "pendulum",
    "protobuf",
    "python",
    "python-dateutil",
    "pytz",
    "pyyaml",
    "rx",
    "setuptools",
    "sqlalchemy",
    "tabulate",
    "toposort",
    "tqdm",
    "typing-compat",
    "tzlocal",
    "watchdog"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "dagster",
   "dagster-meta"
  ]
 },
 "pinning_version": "2022.01.13.20.46.10",
 "pre_pr_migrator_attempts": {},
 "pre_pr_migrator_status": {},
 "raw_meta_yaml": "{% set version = \"0.13.13\" %}\n{% set build_number = 0 %}\n\n# TODO: more elegant way to get at CONDA_SUBDIR\n{% set on_linux_py37 = PY_VER == \"3.7\" and \"linux-64\" in compiler(\"c\") %}\n{% set on_linux_py38 = PY_VER == \"3.8\" and \"linux-64\" in compiler(\"c\") %}\n{% set on_linux_py39 = PY_VER == \"3.9\" and \"linux-64\" in compiler(\"c\") %}\n\npackage:\n  name: dagster-meta\n  version: {{ version }}\n\nsource:\n  # this should always be built\n  - folder: dagster\n    url: https://pypi.io/packages/source/d/dagster/dagster-{{ version }}.tar.gz\n    sha256: 2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125\n\n  {% if on_linux_py37 or on_linux_py38 %}\n  # these are generally safe to build wherever, but are also required for special builds\n  - folder: dagster-graphql\n    url: https://pypi.io/packages/source/d/dagster-graphql/dagster-graphql-{{ version }}.tar.gz\n    sha256: 59bded7a54aa22375270f9c62cd380e414f5de71b17297d3a1a5e233eb7413b8\n  {% endif %}\n\n  {% if on_linux_py37 %}\n  # these are problematic, and presently build only/most reliably on linux/37\n  # along with their dependencies. always download them anyway so they can be found\n  # when rendering the recipe to fetch the shas\n  - folder: dagster-airflow\n    url: https://pypi.io/packages/source/d/dagster-airflow/dagster-airflow-{{ version }}.tar.gz\n    sha256: 0bb9ff6bb22b85e1250e14ffd5d7b26f90874753d1aed9d72c4b3ea5ba2a4464\n\n  - folder: dagster-celery\n    url: https://pypi.io/packages/source/d/dagster-celery/dagster-celery-{{ version }}.tar.gz\n    sha256: 251e94e42744f0b43d74190e2fcda6cd84d8bda875fe305a242c2f993f4dec2c\n\n  - folder: dagster-celery-docker\n    url: https://pypi.io/packages/source/d/dagster-celery-docker/dagster-celery-docker-{{ version }}.tar.gz\n    sha256: 5b9bd84aec69d433a2b8df323918a2b23610e029dc054ea8666ad719b979bb02\n\n  - folder: dagster-dask\n    url: https://pypi.io/packages/source/d/dagster-dask/dagster-dask-{{ version }}.tar.gz\n    sha256: 7a67f16ecddcd0b96615e8189f2a24e257a8538bd65a200dc17872ec96af0de4\n\n  - folder: dagster-pyspark\n    url: https://pypi.io/packages/source/d/dagster-pyspark/dagster-pyspark-{{ version }}.tar.gz\n    sha256: d14388c145cdf60f9245ab17f4cb6c1421068685c62c267fa7da6376cf61b6e1\n\n  - folder: dagster-spark\n    url: https://pypi.io/packages/source/d/dagster-spark/dagster-spark-{{ version }}.tar.gz\n    sha256: 1e41eedf93a83c6d069edac62b4c1f3e0818b82daa4b662064466a660e361b1d\n\n  - folder: dagstermill\n    url: https://pypi.io/packages/source/d/dagstermill/dagstermill-{{ version }}.tar.gz\n    sha256: 186c5f3027b41c529a14e22b4f2df5a4368917438023922097909cdbd7ef087e\n\n  - folder: dagster-k8s\n    url: https://pypi.io/packages/source/d/dagster-k8s/dagster-k8s-{{ version }}.tar.gz\n    sha256: 1fd0297c8c3172c6c443fb5c48938ed77afb0e1db462b11130e1a24e1daa71fe\n\n  - folder: dagster-celery-k8s\n    url: https://pypi.io/packages/source/d/dagster-celery-k8s/dagster-celery-k8s-{{ version }}.tar.gz\n    sha256: 3334195e51af6b4f2ba286ebd395f3cb5efd425441205c1b615b3fbe36d54b13\n\n  - folder: dagster-snowflake\n    url: https://pypi.io/packages/source/d/dagster-snowflake/dagster-snowflake-{{ version }}.tar.gz\n    sha256: ec33d459074143cdd28669ea7c0fda9cdd70af66c125e8157c2f9da84e31316f\n  {% endif %}\n\n  {% if on_linux_py38 %}\n  # these are generally safe to build wherever, but can be built most quickly on linux/38\n  - folder: dagit\n    url: https://pypi.io/packages/source/d/dagit/dagit-{{ version }}.tar.gz\n    sha256: 199ac239c3f58098fd8c1540812787c81cb57f2dc59de5783e7c3addfef93f84\n\n  - folder: dagster-shell\n    url: https://pypi.io/packages/source/d/dagster-shell/dagster-shell-{{ version }}.tar.gz\n    sha256: 6a72f1013f30c4c65b508d3aa543197901f9d1001c72bd3ffe7521124e8ae711\n\n  - folder: dagster-datadog\n    url: https://pypi.io/packages/source/d/dagster-datadog/dagster-datadog-{{ version }}.tar.gz\n    sha256: a14f407dde2b37216e9ec8b8b54953fc0a5da1f8648a989ef6e2b1c5f7012b25\n\n  - folder: dagster-dbt\n    url: https://pypi.io/packages/source/d/dagster-dbt/dagster-dbt-{{ version }}.tar.gz\n    sha256: c383edc1934e9618459fa5e4599170b2b2eda1ffef17b9d643a8ff5c4e629726\n\n  - folder: dagster-docker\n    url: https://pypi.io/packages/source/d/dagster-docker/dagster-docker-{{ version }}.tar.gz\n    sha256: 54908b27049a9eb9408daef69d672b6e369ce208dfea8d6a454a37096b503895\n\n  - folder: dagster-fivetran\n    url: https://pypi.io/packages/source/d/dagster-fivetran/dagster-fivetran-{{ version }}.tar.gz\n    sha256: 860ddaf32a65bbf1f8c5f2c642432ddd93c3413574f29f393ad08192c3d57ac0\n\n  - folder: dagster-ge\n    url: https://pypi.io/packages/source/d/dagster-ge/dagster-ge-{{ version }}.tar.gz\n    sha256: e65ed17f105e5c2735ba4cc9f758c856c46438db3c6e2ee328b307493110d8c3\n\n  - folder: dagster-github\n    url: https://pypi.io/packages/source/d/dagster-github/dagster-github-{{ version }}.tar.gz\n    sha256: 441afce2770cc3b68f06ea9820ed9ac6303a846c6cb5aeec3b97ab8e183d04a0\n\n  - folder: dagster-gcp\n    url: https://pypi.io/packages/source/d/dagster-gcp/dagster-gcp-{{ version }}.tar.gz\n    sha256: 4019a9d62a9b798e59f6cb7eb85e89ecd5bdb2cd1d3a673940d6f1da8bc2181c\n\n  - folder: dagster-mlflow\n    url: https://pypi.io/packages/source/d/dagster-mlflow/dagster-mlflow-{{ version }}.tar.gz\n    sha256: 43c5601ebd99348da3fc87c35b49c588d91c57313a6fc1be8abf0ee72f0a47bf\n\n  - folder: dagster-pandas\n    url: https://pypi.io/packages/source/d/dagster-pandas/dagster-pandas-{{ version }}.tar.gz\n    sha256: 2e91e99e5c25d7270607ac3665fdb07bf8a4232dab2e0e0b8d079feb688357e4\n  {% endif %}\n\n  {% if on_linux_py39 %}\n  - folder: dagster-mysql\n    url: https://pypi.io/packages/source/d/dagster-mysql/dagster-mysql-{{ version }}.tar.gz\n    sha256: bb494192322322ab7e609c2a1ec6948b2367933554522c06ecab1c0d5d7d6a34\n\n  - folder: dagster-msteams\n    url: https://pypi.io/packages/source/d/dagster-msteams/dagster-msteams-{{ version }}.tar.gz\n    sha256: 3092828333dfa1505a820363748f93ea2ca6638c053262e0ba7a3c7da076e76a\n\n  - folder: dagster-pagerduty\n    url: https://pypi.io/packages/source/d/dagster-pagerduty/dagster-pagerduty-{{ version }}.tar.gz\n    sha256: b8dba31a82e7a040955dbfe6407f3f755a0e8b32f7e1d0e62bab3ec822829425\n\n  - folder: dagster-papertrail\n    url: https://pypi.io/packages/source/d/dagster-papertrail/dagster-papertrail-{{ version }}.tar.gz\n    sha256: 5549ec482620e3be58ae61ff0b6c83ea9264875a4f178754f4109695bbe135bb\n\n  - folder: dagster-postgres\n    url: https://pypi.io/packages/source/d/dagster-postgres/dagster-postgres-{{ version }}.tar.gz\n    sha256: b965093b2e3871eee54127b759aaa01c01a473afd4467f2a012711756ac3a3df\n\n  - folder: dagster-prometheus\n    url: https://pypi.io/packages/source/d/dagster-prometheus/dagster-prometheus-{{ version }}.tar.gz\n    sha256: be66123fc72c6c767caa761d5c400be9006c6c0b1122b9611429b2775d865579\n\n  - folder: dagster-slack\n    url: https://pypi.io/packages/source/d/dagster-slack/dagster-slack-{{ version }}.tar.gz\n    sha256: f69d27601f22be3cbad5a1b5d7fbea24c56826070916b000733d1e8b1dc548f5\n\n  - folder: dagster-ssh\n    url: https://pypi.io/packages/source/d/dagster-ssh/dagster-ssh-{{ version }}.tar.gz\n    sha256: 66cb85fe5399bf6e798db8e68e964325b166d60c32f800b365f980cd0a97034c\n\n  - folder: dagster-twilio\n    url: https://pypi.io/packages/source/d/dagster-twilio/dagster-twilio-{{ version }}.tar.gz\n    sha256: eb16a2313b14c2abcfd5a28044d9d53b55c53f17f25fef52d03b05e4625eadc6\n  {% endif %}\n\nbuild:\n  number: {{ build_number }}\n\n\nrequirements:\n  host:\n    - python\n  run:\n    - python\n\n\ntest:\n  commands:\n    - echo \"TODO\"\n\n\noutputs:\n  # all platform/python versions\n  - name: dagster\n    build:\n      number: {{ build_number }}\n      entry_points:\n        - dagster = dagster.cli:main\n        - dagster-daemon = dagster.daemon.cli:main\n      script: cd dagster && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python\n      run:\n        - alembic >=1.2.1,!=1.6.3,<1.7.0\n        - click >=5.0\n        - coloredlogs >=6.1,<=14.0\n        - contextvars  # [py<37]\n        - croniter >=0.3.34\n        - docstring_parser\n        - grpcio >=1.32.0\n        - grpcio-health-checking >=1.32.0\n        - jinja2 <3\n        - packaging >=20.9\n        - pendulum\n        - protobuf >=3.13.0\n        - psutil >=1.0  # [win]\n        - python\n        - python-dateutil\n        - pytz\n        - pywin32 !=226  # [win]\n        - pyyaml >=5.1\n        - rx >=1.6,<2\n        - setuptools  # undeclared dep\n        - sqlalchemy >=1.0\n        - tabulate\n        - toposort >=1.0\n        - tqdm\n        - typing-compat\n        - tzlocal >=1.5,<2  # from pendulum\n        - watchdog >=0.8.3\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster\n        - dagster.api\n        - dagster.check\n        - dagster.cli\n        - dagster.config\n        - dagster.core.asset_defs\n        - dagster.core.definitions\n        - dagster.core.events\n        - dagster.core.execution\n        - dagster.core.executor\n        - dagster.core.host_representation\n        - dagster.core.instance\n        - dagster.core.launcher\n        - dagster.core.run_coordinator\n        - dagster.core.scheduler\n        - dagster.core.selector\n        - dagster.core.snap\n        - dagster.core.storage\n        - dagster.core.system_config\n        - dagster.core.types\n        - dagster.core.workspace\n        - dagster.daemon\n        - dagster.grpc\n        - dagster.loggers\n        - dagster.scheduler\n        - dagster.seven\n        - dagster.utils\n      commands:\n        - python -m pip check\n        - dagster --help\n        - dagster-daemon --help\n\n    about:\n      home: https://github.com/dagster-io/dagster\n      license: Apache-2.0\n      license_family: APACHE\n      summary: The data orchestration platform built for productivity.\n      doc_url: https://dagster.readthedocs.io\n      license_file: dagster/LICENSE\n      description: |\n        Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\n        then test locally and run anywhere. With a unified view of pipelines and the assets they produce,\n        Dagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\n        Dagster is designed for data platform engineers, data engineers, and full-stack data scientists.\n        Building a data platform with Dagster makes your stakeholders more independent and your systems\n        more robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n\n\n  {% if on_linux_py37 or on_linux_py38 %}\n  # needed by both\n  - name: dagster-graphql\n    build:\n      number: {{ build_number }}\n      noarch: python\n      entry_points:\n        - dagster-graphql = dagster_graphql.cli:main\n      script: cd dagster-graphql && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - gevent\n        - gevent-websocket >=0.10.1\n        - graphene >=2.1.3,<3\n        - graphql-core >=2.1,<3\n        - python >=3.6\n        - requests\n        - gql <3\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_graphql\n        - dagster_graphql.client\n        - dagster_graphql.schema\n      commands:\n        - dagster-graphql --help\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-graphql\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-graphql/LICENSE\n      summary: The GraphQL frontend to python dagster.\n  {% endif %}\n\n  {% if on_linux_py37 %}\n  - name: dagster-celery\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-celery && {{ PYTHON }} -m pip install . -vv --no-deps\n      entry_points:\n        - dagster-celery = dagster_celery.cli:main\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - celery >=4.3.0\n        # TODO: maybe remove after https://github.com/conda-forge/celery-feedstock/pull/51\n        - click >=5.0,<9\n        - dagster {{ version }}.*\n        - dagster-graphql {{ version }}.*\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n        # to get viable intersecting click ranges\n        - celery >=5.1.2\n      imports:\n        - dagster_celery\n      commands:\n        - dagster-celery --help\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-celery/LICENSE\n      summary: Package for using Celery as Dagster's execution engine.\n\n  - name: dagster-celery-docker\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-celery-docker && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - dagster-graphql {{ version }}.*\n        - dagster-celery {{ version }}.*\n        - docker-py\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n        # to get viable intersecting click ranges\n        - celery >=5.1.2\n      imports:\n        - dagster_celery_docker\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-docker\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-celery-docker/LICENSE\n      summary: A Dagster integration for celery-docker\n\n  - name: dagster-celery-k8s\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-celery-k8s && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - dagster-celery {{ version }}.*\n        - dagster-k8s {{ version }}.*\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n        # to get viable intersecting click ranges\n        - celery >=5.1.2\n      imports:\n        - dagster_celery_k8s\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/blob/master/python_modules/dagster-celery-k8s\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-celery-k8s/LICENSE\n      summary: A Dagster integration for celery-k8s-executor\n\n  - name: dagster-k8s\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-k8s && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python-kubernetes\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_k8s\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-k8s\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-k8s/LICENSE\n      summary: A Dagster integration for k8s\n\n  - name: dagster-dask\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-dask && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - bokeh\n        - dagster {{ version }}.*\n        - dask >=1.2.2\n        - distributed >=1.28.1\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_dask\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-dask\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-dask/LICENSE\n      summary: Package for using Dask as Dagster's execution engine.\n  {% endif %}\n\n  {% if on_linux_py37 %}\n  # issues with python 3.8\n  - name: dagster-pyspark\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-pyspark && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - dagster-spark {{ version }}.*\n        - pyspark\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_pyspark\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-pyspark\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-pyspark/LICENSE\n      summary: Package for PySpark Dagster framework components.\n\n  - name: dagster-spark\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-spark && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_spark\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-spark\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-spark/LICENSE\n      summary: Package for Spark Dagster framework components.\n\n  # issues with python 2.7\n  - name: dagstermill\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagstermill && {{ PYTHON }} -m pip install . -vv --no-deps\n      entry_points:\n        - dagstermill = dagstermill.cli:main\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - ipykernel >=4.9.0,!=5.4.0,!=5.4.1\n        - packaging >=20.5\n        - papermill >=1.0.0\n        - python >=3.6\n        - scrapbook >=0.5\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagstermill\n      commands:\n        - dagstermill --help\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/dagstermill\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagstermill/LICENSE\n      summary: A Dagster integration for papermill\n\n  # issues with python 3.8\n  - name: dagster-airflow\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-airflow && {{ PYTHON }} -m pip install . -vv --no-deps\n      entry_points:\n        - dagster-airflow = dagster_airflow.cli:main\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - airflow\n        - dagster {{ version }}.*\n        - docker-py\n        - lazy-object-proxy\n        - pendulum 1.4.4\n        - python >=3.6\n        - python-dateutil >=2.8.0\n        - typing_extensions\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_airflow\n      commands:\n        - dagster-airflow --help\n        # TODO: flask-admin 1.5.4 requires enum34, which is not installed.\n        # - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-airflow\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-airflow/LICENSE\n      summary: Airflow plugin for Dagster\n\n  - name: dagster-snowflake\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-snowflake && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python >=3.6\n        - snowflake-connector-python >=2.1.0\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_snowflake\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-snowflake\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-snowflake/LICENSE\n      summary: Package for Snowflake Dagster framework components.\n  {% endif %}\n\n  {% if on_linux_py38 %}\n  # would build wherever, but build fastest here (or needs pandas)\n  - name: dagit\n    build:\n      number: {{ build_number }}\n      noarch: python\n      entry_points:\n        - dagit = dagit.cli:main\n        - dagit-debug = dagit.debug:main\n      script: cd dagit && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - click >=7.0,<9.0\n        - dagster {{ version }}.*\n        - dagster-graphql {{ version }}.*\n        - flask >=0.12.4,<2.0.0\n        - flask-cors >=3.0.6\n        - flask-graphql >=2.0.0\n        - flask-sockets >=0.2.1\n        - gevent\n        - gevent-websocket >=0.10.1\n        - graphql-ws >=0.3.0,<0.4.0\n        - nbconvert >=5.4.0,<6.0.0\n        - python >=3.6\n        - pyyaml\n        - requests\n        - watchdog >=0.8.3\n        - werkzeug <2.0.0\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagit\n        - dagit.schema\n        - dagit.templates\n      commands:\n        - python -m pip check\n        - dagit --help\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/dagit\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagit/LICENSE\n      summary: Dagster UI\n\n  - name: dagster-shell\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-shell && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_shell\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-shell\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-shell/LICENSE\n      summary: Package for Dagster shell ops.\n\n  - name: dagster-datadog\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-datadog && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - datadog\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_datadog\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-datadog\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-datadog/LICENSE\n      summary: Package for datadog Dagster framework components.\n\n  - name: dagster-dbt\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-dbt && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - attrs\n        - dagster {{ version }}.*\n        - dagster-pandas {{ version }}.*\n        - pandas\n        - requests\n        - agate <1.6.2\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_dbt\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-dbt\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster/LICENSE\n      summary: A Dagster integration for dbt\n\n  - name: dagster-fivetran\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-fivetran && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python >=3.6\n        - requests\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_fivetran\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-fivetran\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-fivetran/LICENSE\n      summary: Package for integrating Fivetran with Dagster.\n\n  - name: dagster-ge\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-ge && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - dagster-pandas {{ version }}.*\n        - great-expectations >=0.11.9,!=0.12.8,!=0.13.17,!=0.13.27\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_ge\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-ge\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-ge/LICENSE\n      summary: Package for GE-specific Dagster framework solid and resource components.\n\n  - name: dagster-github\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-github && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - cryptography >=1.4\n        - dagster {{ version }}.*\n        - pyjwt\n        - python >=3.6\n        - requests\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_github\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-github\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-github/LICENSE\n      summary: Github plugin for Dagster\n\n  - name: dagster-docker\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-docker && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - docker-py\n        - docker-image-py\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_docker\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-docker\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-docker/LICENSE\n      summary: A Dagster integration for docker\n\n\n  # these _would_ build on py37_0, except conda-build tries to test them with py38\n  # issues with win/python 2.7\n  - name: dagster-gcp\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-gcp && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - dagster-pandas {{ version }}.*\n        - google-api-python-client <2.0.0\n        # TODO as of #39 google-api-core 1.20.0, importing bigquery presently fails with\n        #\n        #   AttributeError: module 'google.api_core' has no attribute 'gapic_v1'`\n        #\n        # which uncovers a whole separate can of worms down to grpcio\n        - google-api-core !=1.20.0\n        - google-cloud-bigquery-core >=1.19\n        - google-cloud-storage\n        - google-resumable-media\n        - oauth2client\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_gcp\n        - dagster_gcp.bigquery\n        - dagster_gcp.dataproc\n        - dagster_gcp.gcs\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-gcp\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-gcp/LICENSE\n      summary: Package for GCP-specific Dagster framework solid and resource components.\n\n  - name: dagster-mlflow\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-mlflow && {{ PYTHON }} -m pip install . -vv --no-deps\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - mlflow\n        - pandas\n        - python >=3.6\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_mlflow\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-mlflow\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-mlflow/LICENSE\n      summary: Package for mlflow Dagster framework components\n\n  - name: dagster-pandas\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-pandas && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - pandas\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_pandas\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-pandas/LICENSE\n      summary: Utilities and examples for working with pandas and dagster, an opinionated framework for expressing data pipelines\n  {% endif %}\n\n  {% if on_linux_py39 %}\n  - name: dagster-mysql\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-mysql && {{ PYTHON }} -m pip install . -vv --no-deps\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - mysql-connector-python\n        - python >=3.6\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_mysql\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-mysql\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-mysql/LICENSE\n      summary: A Dagster integration for MySQL\n\n  - name: dagster-msteams\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-msteams && {{ PYTHON }} -m pip install . -vv --no-deps\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python >=3.6\n        - requests >=2,<3\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_msteams\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-msteams\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-msteams/LICENSE\n      summary: A Microsoft Teams client resource for posting to Microsoft Teams\n\n  - name: dagster-pagerduty\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-pagerduty && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - pypd\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_pagerduty\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-pagerduty\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-pagerduty/LICENSE\n      summary: Package for pagerduty Dagster framework components.\n\n  - name: dagster-papertrail\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-papertrail && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_papertrail\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-papertrail\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-papertrail/LICENSE\n      summary: Package for papertrail Dagster framework components.\n\n  - name: dagster-postgres\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-postgres && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - psycopg2-binary\n        - python >=3.6\n\n    test:\n      imports:\n        - dagster_postgres\n      commands:\n        - pip check\n      requires:\n        - pip\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-postgres\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-postgres/LICENSE\n      summary: A Dagster integration for postgres\n\n  - name: dagster-prometheus\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-prometheus && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - prometheus_client\n        - python >=3.6\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_prometheus\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-prometheus\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-prometheus/LICENSE\n      summary: A Dagster integration for prometheus\n\n  - name: dagster-slack\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-slack && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python >=3.6\n        - slack-sdk\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_slack\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-slack\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-slack/LICENSE\n      summary: A Slack client resource for posting to Slack\n\n  - name: dagster-ssh\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-ssh && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - paramiko\n        - python >=3.6\n        - sshtunnel\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_ssh\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-ssh\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-ssh/LICENSE\n      summary: Package for ssh Dagster framework components.\n\n  - name: dagster-twilio\n    build:\n      number: {{ build_number }}\n      noarch: python\n      script: cd dagster-twilio && {{ PYTHON }} -m pip install . -vv --no-deps\n\n    requirements:\n      host:\n        - pip\n        - python >=3.6\n      run:\n        - dagster {{ version }}.*\n        - python >=3.6\n        - twilio\n\n    test:\n      requires:\n        - pip\n      imports:\n        - dagster_twilio\n      commands:\n        - python -m pip check\n\n    about:\n      home: https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-twilio\n      license: Apache-2.0\n      license_family: APACHE\n      license_file: dagster-twilio/LICENSE\n      summary: A Dagster integration for twilio\n  {% endif %}\n\n\nabout:\n  home: https://github.com/dagster-io\n  summary: The data orchestration platform built for productivity.\n  license: Apache-2.0\n  license_family: APACHE\n  license_file: dagster/LICENSE\n  doc_url: https://dagster.readthedocs.io\n  description: >-\n    Dagster is a system for building modern data applications. Combining an elegant programming model and beautiful tools, Dagster allows infrastructure engineers, data engineers, and data scientists to seamlessly collaborate to process and produce the trusted, reliable data needed in today's world.\n\nextra:\n  feedstock-name: dagster\n  recipe-maintainers:\n    - xhochy\n    - bollwyvl\n    - mgasner\n",
 "req": {
  "__set__": true,
  "elements": [
   "alembic",
   "click",
   "coloredlogs",
   "croniter",
   "docstring_parser",
   "grpcio",
   "grpcio-health-checking",
   "jinja2",
   "packaging",
   "pendulum",
   "pip",
   "protobuf",
   "psutil",
   "python",
   "python-dateutil",
   "pytz",
   "pywin32",
   "pyyaml",
   "rx",
   "setuptools",
   "sqlalchemy",
   "tabulate",
   "toposort",
   "tqdm",
   "typing-compat",
   "tzlocal",
   "watchdog"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "alembic",
    "click",
    "coloredlogs",
    "croniter",
    "docstring_parser",
    "grpcio",
    "grpcio-health-checking",
    "jinja2",
    "packaging",
    "pendulum",
    "protobuf",
    "psutil",
    "python",
    "python-dateutil",
    "pytz",
    "pywin32",
    "pyyaml",
    "rx",
    "setuptools",
    "sqlalchemy",
    "tabulate",
    "toposort",
    "tqdm",
    "typing-compat",
    "tzlocal",
    "watchdog"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "smithy_version": "3.16.1",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "alembic >=1.2.1,!=1.6.3,<1.7.0",
    "click >=5.0",
    "coloredlogs >=6.1,<=14.0",
    "croniter >=0.3.34",
    "docstring_parser",
    "grpcio >=1.32.0",
    "grpcio-health-checking >=1.32.0",
    "jinja2 <3",
    "packaging >=20.9",
    "pendulum",
    "protobuf >=3.13.0",
    "psutil >=1.0",
    "python",
    "python-dateutil",
    "pytz",
    "pywin32 !=226",
    "pyyaml >=5.1",
    "rx >=1.6,<2",
    "setuptools",
    "sqlalchemy >=1.0",
    "tabulate",
    "toposort >=1.0",
    "tqdm",
    "typing-compat",
    "tzlocal >=1.5,<2",
    "watchdog >=0.8.3"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz",
 "version": "0.13.13",
 "win_64_meta_yaml": {
  "about": {
   "description": "Dagster is a system for building modern data applications. Combining an elegant programming model and beautiful tools, Dagster allows infrastructure engineers, data engineers, and data scientists to seamlessly collaborate to process and produce the trusted, reliable data needed in today's world.",
   "doc_url": "https://dagster.readthedocs.io",
   "home": "https://github.com/dagster-io",
   "license": "Apache-2.0",
   "license_family": "APACHE",
   "license_file": "dagster/LICENSE",
   "summary": "The data orchestration platform built for productivity."
  },
  "build": {
   "number": "0"
  },
  "extra": {
   "feedstock-name": "dagster",
   "recipe-maintainers": [
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner",
    "xhochy",
    "bollwyvl",
    "mgasner"
   ]
  },
  "outputs": [
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "psutil >=1.0",
      "python",
      "python-dateutil",
      "pytz",
      "pywin32 !=226",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "psutil >=1.0",
      "python",
      "python-dateutil",
      "pytz",
      "pywin32 !=226",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "psutil >=1.0",
      "python",
      "python-dateutil",
      "pytz",
      "pywin32 !=226",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   },
   {
    "about": {
     "description": "Dagster lets you define pipelines in terms of the data flow between reusable, logical components,\nthen test locally and run anywhere. With a unified view of pipelines and the assets they produce,\nDagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.\n\nDagster is designed for data platform engineers, data engineers, and full-stack data scientists.\nBuilding a data platform with Dagster makes your stakeholders more independent and your systems\nmore robust. Developing data pipelines with Dagster makes testing easier and deploying faster.\n",
     "doc_url": "https://dagster.readthedocs.io",
     "home": "https://github.com/dagster-io/dagster",
     "license": "Apache-2.0",
     "license_family": "APACHE",
     "license_file": "dagster/LICENSE",
     "summary": "The data orchestration platform built for productivity."
    },
    "build": {
     "entry_points": [
      "dagster = dagster.cli:main",
      "dagster-daemon = dagster.daemon.cli:main"
     ],
     "number": "0",
     "script": "cd dagster && /usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/python.exe -m pip install . -vv --no-deps"
    },
    "name": "dagster",
    "requirements": {
     "host": [
      "pip",
      "python"
     ],
     "run": [
      "alembic >=1.2.1,!=1.6.3,<1.7.0",
      "click >=5.0",
      "coloredlogs >=6.1,<=14.0",
      "croniter >=0.3.34",
      "docstring_parser",
      "grpcio >=1.32.0",
      "grpcio-health-checking >=1.32.0",
      "jinja2 <3",
      "packaging >=20.9",
      "pendulum",
      "protobuf >=3.13.0",
      "psutil >=1.0",
      "python",
      "python-dateutil",
      "pytz",
      "pywin32 !=226",
      "pyyaml >=5.1",
      "rx >=1.6,<2",
      "setuptools",
      "sqlalchemy >=1.0",
      "tabulate",
      "toposort >=1.0",
      "tqdm",
      "typing-compat",
      "tzlocal >=1.5,<2",
      "watchdog >=0.8.3"
     ]
    },
    "test": {
     "commands": [
      "python -m pip check",
      "dagster --help",
      "dagster-daemon --help"
     ],
     "imports": [
      "dagster",
      "dagster.api",
      "dagster.check",
      "dagster.cli",
      "dagster.config",
      "dagster.core.asset_defs",
      "dagster.core.definitions",
      "dagster.core.events",
      "dagster.core.execution",
      "dagster.core.executor",
      "dagster.core.host_representation",
      "dagster.core.instance",
      "dagster.core.launcher",
      "dagster.core.run_coordinator",
      "dagster.core.scheduler",
      "dagster.core.selector",
      "dagster.core.snap",
      "dagster.core.storage",
      "dagster.core.system_config",
      "dagster.core.types",
      "dagster.core.workspace",
      "dagster.daemon",
      "dagster.grpc",
      "dagster.loggers",
      "dagster.scheduler",
      "dagster.seven",
      "dagster.utils"
     ],
     "requires": [
      "pip"
     ]
    }
   }
  ],
  "package": {
   "name": "dagster-meta",
   "version": "0.13.13"
  },
  "requirements": {
   "host": [
    "python",
    "python",
    "python",
    "python"
   ],
   "run": [
    "python",
    "python",
    "python",
    "python"
   ]
  },
  "source": [
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   },
   {
    "folder": "dagster",
    "sha256": "2691a488e26a49a881d62912eed72ba2f183252c806704b3cb2bb84f4aa40125",
    "url": "https://pypi.io/packages/source/d/dagster/dagster-0.13.13.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\"",
    "echo \"TODO\""
   ]
  }
 },
 "win_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "alembic",
    "click",
    "coloredlogs",
    "croniter",
    "docstring_parser",
    "grpcio",
    "grpcio-health-checking",
    "jinja2",
    "packaging",
    "pendulum",
    "protobuf",
    "psutil",
    "python",
    "python-dateutil",
    "pytz",
    "pywin32",
    "pyyaml",
    "rx",
    "setuptools",
    "sqlalchemy",
    "tabulate",
    "toposort",
    "tqdm",
    "typing-compat",
    "tzlocal",
    "watchdog"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 }
}