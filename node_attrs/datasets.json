{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/548443676.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.2.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/554287470.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.2.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/573737031.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.3.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/584215386.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/584716044.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/595731749.json"
   },
   "data": {
    "bot_rerun": 1626462927.3905013,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.5.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/691697384.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.9.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/694494049.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/695063241.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/695143013.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.10.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/700443718.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.11.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/733252480.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.12.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/734844563.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.12.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/757815833.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.13.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/758459325.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.13.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/758558869.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.13.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "datasets",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "Datasets is a lightweight library providing one-line dataloaders for many\npublic datasets and one liners to download and pre-process any of the number\nof datasets major public datasets provided on the HuggingFace Datasets Hub.\nDatasets are ready to use in a dataloader for training/evaluating a ML model\n(Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\nsimple, fast, and reproducible data pre-processing for the above public\ndatasets as well as your own local datasets in CSV/JSON/text.\n",
   "dev_url": "https://github.com/huggingface/datasets",
   "doc_url": "https://huggingface.co/docs/datasets/",
   "home": "https://github.com/huggingface/datasets",
   "license": "Apache-2.0",
   "license_family": "Apache",
   "license_file": "LICENSE",
   "summary": "HuggingFace/Datasets is an open library of NLP datasets."
  },
  "build": {
   "entry_points": [
    "datasets-cli=datasets.commands.datasets_cli:main"
   ],
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "oblute",
    "Tata17",
    "thewchan",
    "mxr-conda",
    "wietsedv"
   ]
  },
  "package": {
   "name": "datasets",
   "version": "1.13.1"
  },
  "requirements": {
   "host": [
    "pip",
    "python >=3.6"
   ],
   "run": [
    "aiohttp",
    "dataclasses",
    "dill",
    "fsspec >=2021.05.0",
    "huggingface_hub >=0.0.14,<0.1.0",
    "importlib-metadata",
    "multiprocess",
    "numpy >=1.17",
    "packaging",
    "pandas",
    "pyarrow >=1.0.0,!=4.0.0",
    "requests >=2.19.0",
    "tqdm >=4.62.1",
    "python >=3.6",
    "python-xxhash"
   ]
  },
  "source": {
   "sha256": "4805ac30aa1ca3b5fbaa9424859015f8cbf228f7b66fb5eef75e30fe673cc12c",
   "url": "https://pypi.io/packages/source/d/datasets/datasets-1.13.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "datasets-cli --help"
   ],
   "imports": [
    "datasets",
    "datasets.commands",
    "datasets.utils"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "aiohttp",
    "dataclasses",
    "dill",
    "fsspec",
    "huggingface_hub",
    "importlib-metadata",
    "multiprocess",
    "numpy",
    "packaging",
    "pandas",
    "pyarrow",
    "python",
    "python-xxhash",
    "requests",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "description": "Datasets is a lightweight library providing one-line dataloaders for many\npublic datasets and one liners to download and pre-process any of the number\nof datasets major public datasets provided on the HuggingFace Datasets Hub.\nDatasets are ready to use in a dataloader for training/evaluating a ML model\n(Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\nsimple, fast, and reproducible data pre-processing for the above public\ndatasets as well as your own local datasets in CSV/JSON/text.\n",
   "dev_url": "https://github.com/huggingface/datasets",
   "doc_url": "https://huggingface.co/docs/datasets/",
   "home": "https://github.com/huggingface/datasets",
   "license": "Apache-2.0",
   "license_family": "Apache",
   "license_file": "LICENSE",
   "summary": "HuggingFace/Datasets is an open library of NLP datasets."
  },
  "build": {
   "entry_points": [
    "datasets-cli=datasets.commands.datasets_cli:main"
   ],
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "oblute",
    "Tata17",
    "thewchan",
    "mxr-conda",
    "wietsedv"
   ]
  },
  "package": {
   "name": "datasets",
   "version": "1.13.1"
  },
  "requirements": {
   "host": [
    "pip",
    "python >=3.6"
   ],
   "run": [
    "aiohttp",
    "dataclasses",
    "dill",
    "fsspec >=2021.05.0",
    "huggingface_hub >=0.0.14,<0.1.0",
    "importlib-metadata",
    "multiprocess",
    "numpy >=1.17",
    "packaging",
    "pandas",
    "pyarrow >=1.0.0,!=4.0.0",
    "requests >=2.19.0",
    "tqdm >=4.62.1",
    "python >=3.6",
    "python-xxhash"
   ]
  },
  "source": {
   "sha256": "4805ac30aa1ca3b5fbaa9424859015f8cbf228f7b66fb5eef75e30fe673cc12c",
   "url": "https://pypi.io/packages/source/d/datasets/datasets-1.13.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "datasets-cli --help"
   ],
   "imports": [
    "datasets",
    "datasets.commands",
    "datasets.utils"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "name": "datasets",
 "new_version": "1.13.2",
 "new_version_attempts": {
  "1.10.0": 1,
  "1.10.1": 1,
  "1.10.2": 1,
  "1.11.0": 1,
  "1.12.0": 1,
  "1.12.1": 1,
  "1.13.0": 1,
  "1.13.1": 1,
  "1.13.2": 1,
  "1.2.0": 1,
  "1.2.1": 1,
  "1.3.0": 1,
  "1.4.0": 1,
  "1.4.1": 1,
  "1.5.0": 1,
  "1.9.0": 1
 },
 "new_version_errors": {},
 "outputs_names": {
  "__set__": true,
  "elements": [
   "datasets"
  ]
 },
 "pinning_version": "2021.10.13.20.28.53",
 "raw_meta_yaml": "{% set name = \"datasets\" %}\n{% set version = \"1.13.1\" %}\n\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 4805ac30aa1ca3b5fbaa9424859015f8cbf228f7b66fb5eef75e30fe673cc12c\n\nbuild:\n  noarch: python\n  number: 0\n  entry_points:\n    - datasets-cli=datasets.commands.datasets_cli:main\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python >=3.6\n  run:\n    - aiohttp\n    - dataclasses\n    - dill\n    - fsspec >=2021.05.0\n    - huggingface_hub >=0.0.14,<0.1.0\n    - importlib-metadata\n    - multiprocess\n    - numpy >=1.17\n    - packaging\n    - pandas\n    - pyarrow >=1.0.0,!=4.0.0\n    - requests >=2.19.0\n    - tqdm >=4.62.1\n    - python >=3.6\n    - python-xxhash\n\ntest:\n  imports:\n    - datasets\n    - datasets.commands\n    - datasets.utils\n  commands:\n    - pip check\n    - datasets-cli --help\n  requires:\n    - pip\n\nabout:\n  home: https://github.com/huggingface/datasets\n  license: Apache-2.0\n  license_family: Apache\n  license_file: LICENSE\n  summary: HuggingFace/Datasets is an open library of NLP datasets.\n  description: |\n    Datasets is a lightweight library providing one-line dataloaders for many\n    public datasets and one liners to download and pre-process any of the number\n    of datasets major public datasets provided on the HuggingFace Datasets Hub.\n    Datasets are ready to use in a dataloader for training/evaluating a ML model\n    (Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\n    simple, fast, and reproducible data pre-processing for the above public\n    datasets as well as your own local datasets in CSV/JSON/text.\n  doc_url: https://huggingface.co/docs/datasets/\n  dev_url: https://github.com/huggingface/datasets\n\nextra:\n  recipe-maintainers:\n    - oblute\n    - Tata17\n    - thewchan\n    - mxr-conda\n    - wietsedv\n",
 "req": {
  "__set__": true,
  "elements": [
   "aiohttp",
   "dataclasses",
   "dill",
   "fsspec",
   "huggingface_hub",
   "importlib-metadata",
   "multiprocess",
   "numpy",
   "packaging",
   "pandas",
   "pip",
   "pyarrow",
   "python",
   "python-xxhash",
   "requests",
   "tqdm"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "aiohttp",
    "dataclasses",
    "dill",
    "fsspec",
    "huggingface_hub",
    "importlib-metadata",
    "multiprocess",
    "numpy",
    "packaging",
    "pandas",
    "pyarrow",
    "python",
    "python-xxhash",
    "requests",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "smithy_version": "3.12",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python >=3.6"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "aiohttp",
    "dataclasses",
    "dill",
    "fsspec >=2021.05.0",
    "huggingface_hub >=0.0.14,<0.1.0",
    "importlib-metadata",
    "multiprocess",
    "numpy >=1.17",
    "packaging",
    "pandas",
    "pyarrow >=1.0.0,!=4.0.0",
    "python >=3.6",
    "python-xxhash",
    "requests >=2.19.0",
    "tqdm >=4.62.1"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/d/datasets/datasets-1.13.1.tar.gz",
 "version": "1.13.1"
}