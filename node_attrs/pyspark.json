{
 "PRed": [
  {
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.3.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/200284320.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Noarch",
    "migrator_version": 0
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/217867002.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.3.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/222685124.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "CompilerRebuild",
    "migrator_version": 1,
    "name": "Python 3.7, GCC 7, R 3.5.1, openBLAS 0.3.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/227841308.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.4.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/266201238.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.4.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/272971155.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.4.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/276478074.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.4.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/312931162.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.4.4"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/372091737.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.4.5"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/428883303.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "2.4.6"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/435239692.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "3.0.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/481530597.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "3.0.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/576686093.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "3.0.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/582940532.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "3.1.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/655274134.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "3.1.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/832194033.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "3.2.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/968680173.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "3.3.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/1098644029.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "3.3.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {
  "provider": {
   "win": "azure"
  }
 },
 "feedstock_name": "pyspark",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "Apache Spark is a fast and general engine for large-scale data processing.",
   "home": "http://spark.apache.org/",
   "license": "Apache-2.0",
   "license_file": "/LICENSE",
   "summary": "Apache Spark"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . --no-deps --ignore-installed -vv "
  },
  "extra": {
   "recipe-maintainers": [
    "parente",
    "quasiben",
    "dbast",
    "mariusvniekerk"
   ]
  },
  "package": {
   "name": "pyspark",
   "version": "3.3.1"
  },
  "requirements": {
   "host": [
    "pip",
    "python >=3.7",
    "setuptools"
   ],
   "run": [
    "numpy >=1.15",
    "pandas >=1.0.5",
    "py4j ==0.10.9.5",
    "pyarrow >=1.0.0",
    "python >=3.7"
   ]
  },
  "source": {
   "patches": [
    "0001-Disable-symlinks-on-Windows.patch"
   ],
   "sha256": "e99fa7de92be406884bfd831c32b9306a3a99de44cfc39a2eefb6ed07445d5fa",
   "url": "https://dist.apache.org/repos/dist/release/spark/spark-3.3.1/pyspark-3.3.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "bash -c \"compgen -c spark && compgen -c pyspark\""
   ],
   "imports": [
    "pyspark",
    "pyspark.cloudpickle",
    "pyspark.ml",
    "pyspark.ml.linalg",
    "pyspark.ml.param",
    "pyspark.mllib",
    "pyspark.mllib.linalg",
    "pyspark.mllib.stat",
    "pyspark.pandas",
    "pyspark.pandas.data_type_ops",
    "pyspark.pandas.indexes",
    "pyspark.pandas.missing",
    "pyspark.pandas.plot",
    "pyspark.pandas.spark",
    "pyspark.pandas.typedef",
    "pyspark.pandas.usage_logging",
    "pyspark.python.pyspark",
    "pyspark.python.lib",
    "pyspark.sql",
    "pyspark.sql.avro",
    "pyspark.sql.pandas",
    "pyspark.streaming",
    "pyspark.bin",
    "pyspark.sbin",
    "pyspark.jars",
    "pyspark.data",
    "pyspark.licenses",
    "pyspark.resource"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "numpy",
    "pandas",
    "py4j",
    "pyarrow",
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "description": "Apache Spark is a fast and general engine for large-scale data processing.",
   "home": "http://spark.apache.org/",
   "license": "Apache-2.0",
   "license_file": "/LICENSE",
   "summary": "Apache Spark"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . --no-deps --ignore-installed -vv "
  },
  "extra": {
   "recipe-maintainers": [
    "parente",
    "quasiben",
    "dbast",
    "mariusvniekerk"
   ]
  },
  "package": {
   "name": "pyspark",
   "version": "3.3.1"
  },
  "requirements": {
   "host": [
    "pip",
    "python >=3.7",
    "setuptools"
   ],
   "run": [
    "numpy >=1.15",
    "pandas >=1.0.5",
    "py4j ==0.10.9.5",
    "pyarrow >=1.0.0",
    "python >=3.7"
   ]
  },
  "source": {
   "patches": [
    "0001-Disable-symlinks-on-Windows.patch"
   ],
   "sha256": "e99fa7de92be406884bfd831c32b9306a3a99de44cfc39a2eefb6ed07445d5fa",
   "url": "https://dist.apache.org/repos/dist/release/spark/spark-3.3.1/pyspark-3.3.1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "bash -c \"compgen -c spark && compgen -c pyspark\""
   ],
   "imports": [
    "pyspark",
    "pyspark.cloudpickle",
    "pyspark.ml",
    "pyspark.ml.linalg",
    "pyspark.ml.param",
    "pyspark.mllib",
    "pyspark.mllib.linalg",
    "pyspark.mllib.stat",
    "pyspark.pandas",
    "pyspark.pandas.data_type_ops",
    "pyspark.pandas.indexes",
    "pyspark.pandas.missing",
    "pyspark.pandas.plot",
    "pyspark.pandas.spark",
    "pyspark.pandas.typedef",
    "pyspark.pandas.usage_logging",
    "pyspark.python.pyspark",
    "pyspark.python.lib",
    "pyspark.sql",
    "pyspark.sql.avro",
    "pyspark.sql.pandas",
    "pyspark.streaming",
    "pyspark.bin",
    "pyspark.sbin",
    "pyspark.jars",
    "pyspark.data",
    "pyspark.licenses",
    "pyspark.resource"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "name": "pyspark",
 "new_version": "3.3.1",
 "new_version_attempts": {
  "2.4.6": 1,
  "3.0.0": 1,
  "3.0.1": 1,
  "3.0.2": 1,
  "3.1.1": 1,
  "3.1.2": 1,
  "3.2.1": 1,
  "3.3.0": 1,
  "3.3.1": 1
 },
 "new_version_errors": {},
 "outputs_names": {
  "__set__": true,
  "elements": [
   "pyspark"
  ]
 },
 "pinning_version": "2022.10.25.08.18.02",
 "raw_meta_yaml": "{% set version = \"3.3.1\" %}\n\npackage:\n  name: pyspark\n  version: {{ version }}\n\nsource:\n  # PyPI has had issues recently with timely releases due to size constraints of tarball;\n  # Building from source runs into StackOverflow errors in CF CI; --> use upstream binary\n  url: https://dist.apache.org/repos/dist/release/spark/spark-{{ version }}/pyspark-{{ version }}.tar.gz\n  sha256: e99fa7de92be406884bfd831c32b9306a3a99de44cfc39a2eefb6ed07445d5fa\n  patches:\n    - 0001-Disable-symlinks-on-Windows.patch\n\nbuild:\n  noarch: python\n  number: 0\n  script: '{{ PYTHON }} -m pip install . --no-deps --ignore-installed -vv '\n\nrequirements:\n  host:\n    - pip\n    - python >=3.7\n    - setuptools\n  run:\n    - numpy >=1.15\n    - pandas >=1.0.5\n    - py4j ==0.10.9.5\n    - pyarrow >=1.0.0\n    - python >=3.7\n\ntest:\n  commands:\n    - pip check\n    - bash -c \"compgen -c spark && compgen -c pyspark\"  # [not win]\n    - where *spark*                                     # [win]\n  imports:\n    - pyspark\n    - pyspark.cloudpickle\n    - pyspark.ml\n    - pyspark.ml.linalg\n    - pyspark.ml.param\n    - pyspark.mllib\n    - pyspark.mllib.linalg\n    - pyspark.mllib.stat\n    - pyspark.pandas\n    - pyspark.pandas.data_type_ops\n    - pyspark.pandas.indexes\n    - pyspark.pandas.missing\n    - pyspark.pandas.plot\n    - pyspark.pandas.spark\n    - pyspark.pandas.typedef\n    - pyspark.pandas.usage_logging\n    - pyspark.python.pyspark\n    - pyspark.python.lib\n    - pyspark.sql\n    - pyspark.sql.avro\n    - pyspark.sql.pandas\n    - pyspark.streaming\n    - pyspark.bin\n    - pyspark.sbin\n    - pyspark.jars\n    - pyspark.data\n    - pyspark.licenses\n    - pyspark.resource\n  requires:\n    - pip\n\nabout:\n  home: http://spark.apache.org/\n  license: Apache-2.0\n  # Not yet available in the pypi release\n  license_file: {{ environ[\"RECIPE_DIR\"] }}/LICENSE\n  summary: Apache Spark\n  description: Apache Spark is a fast and general engine for large-scale data processing.\n\nextra:\n  recipe-maintainers:\n    - parente\n    - quasiben\n    - dbast\n    - mariusvniekerk\n",
 "req": {
  "__set__": true,
  "elements": [
   "numpy",
   "pandas",
   "pip",
   "py4j",
   "pyarrow",
   "python",
   "setuptools"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python",
    "setuptools"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "numpy",
    "pandas",
    "py4j",
    "pyarrow",
    "python"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "smithy_version": "3.21.2",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python >=3.7",
    "setuptools"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "numpy >=1.15",
    "pandas >=1.0.5",
    "py4j ==0.10.9.5",
    "pyarrow >=1.0.0",
    "python >=3.7"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://dist.apache.org/repos/dist/release/spark/spark-3.3.1/pyspark-3.3.1.tar.gz",
 "version": "3.3.1"
}