{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/796805403.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.1.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/822434736.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.1.4"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/879946837.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.1.5"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "main",
 "conda-forge.yml": {},
 "feedstock_name": "spacy-transformers",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "This package provides spaCy components and architectures to use transformer\nmodels via Hugging Face's transformers in spaCy. The result is convenient\naccess to state-of-the-art transformer architectures, such as BERT, GPT-2,\nXLNet, etc.\n",
   "dev_url": "https://github.com/explosion/spacy-transformers",
   "doc_url": "https://github.com/explosion/spacy-transformers",
   "home": "https://spacy.io",
   "license": "MIT",
   "license_file": "LICENSE",
   "summary": "Use pretrained transformers like BERT, XLNet and GPT-2 in spaCy"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "honnibal",
    "ines",
    "adrianeboyd"
   ]
  },
  "package": {
   "name": "spacy-transformers",
   "version": "1.1.4"
  },
  "requirements": {
   "host": [
    "python >=3.6",
    "pip"
   ],
   "run": [
    "python >=3.6",
    "spacy >=3.1.3,<4.0.0",
    "transformers >=3.4.0,<4.12.0",
    "pytorch >=1.6.0",
    "srsly >=2.4.0,<3.0.0",
    "spacy-alignments >=0.7.2,<1.0.0"
   ]
  },
  "source": {
   "sha256": "1b4f5b6625d3744bae92f2a33ce6184d6fc1d7d778d3a412443394e597e50c35",
   "url": "https://pypi.io/packages/source/s/spacy-transformers/spacy-transformers-1.1.4.tar.gz"
  },
  "test": {
   "imports": [
    "spacy_transformers"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python",
    "pytorch",
    "spacy",
    "spacy-alignments",
    "srsly",
    "transformers"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "description": "This package provides spaCy components and architectures to use transformer\nmodels via Hugging Face's transformers in spaCy. The result is convenient\naccess to state-of-the-art transformer architectures, such as BERT, GPT-2,\nXLNet, etc.\n",
   "dev_url": "https://github.com/explosion/spacy-transformers",
   "doc_url": "https://github.com/explosion/spacy-transformers",
   "home": "https://spacy.io",
   "license": "MIT",
   "license_file": "LICENSE",
   "summary": "Use pretrained transformers like BERT, XLNet and GPT-2 in spaCy"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda3/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "honnibal",
    "ines",
    "adrianeboyd"
   ]
  },
  "package": {
   "name": "spacy-transformers",
   "version": "1.1.4"
  },
  "requirements": {
   "host": [
    "python >=3.6",
    "pip"
   ],
   "run": [
    "python >=3.6",
    "spacy >=3.1.3,<4.0.0",
    "transformers >=3.4.0,<4.12.0",
    "pytorch >=1.6.0",
    "srsly >=2.4.0,<3.0.0",
    "spacy-alignments >=0.7.2,<1.0.0"
   ]
  },
  "source": {
   "sha256": "1b4f5b6625d3744bae92f2a33ce6184d6fc1d7d778d3a412443394e597e50c35",
   "url": "https://pypi.io/packages/source/s/spacy-transformers/spacy-transformers-1.1.4.tar.gz"
  },
  "test": {
   "imports": [
    "spacy_transformers"
   ]
  }
 },
 "name": "spacy-transformers",
 "new_version": "1.1.5",
 "new_version_attempts": {
  "1.1.3": 1,
  "1.1.4": 1,
  "1.1.5": 1
 },
 "new_version_errors": {},
 "outputs_names": {
  "__set__": true,
  "elements": [
   "spacy-transformers"
  ]
 },
 "pinning_version": "2022.03.14.13.58.01",
 "raw_meta_yaml": "{% set name = \"spacy-transformers\" %}\n{% set module_name = \"spacy_transformers\" %}\n{% set version = \"1.1.4\" %}\n\npackage:\n  name: {{ name }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 1b4f5b6625d3744bae92f2a33ce6184d6fc1d7d778d3a412443394e597e50c35\n\n\nbuild:\n  noarch: python\n  number: 0\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - python >=3.6\n    - pip\n  run:\n    - python >=3.6\n    - spacy >=3.1.3,<4.0.0\n    - transformers >=3.4.0,<4.12.0\n    - pytorch >=1.6.0\n    - srsly >=2.4.0,<3.0.0\n    - spacy-alignments >=0.7.2,<1.0.0\n\ntest:\n#  requires:\n#    - pytest\n  imports:\n    - {{ module_name }}\n#  commands:\n#    - python -m pytest --tb=native --pyargs {{ module_name }}\n\nabout:\n  home: https://spacy.io\n  license: MIT\n  license_file: LICENSE\n  summary: Use pretrained transformers like BERT, XLNet and GPT-2 in spaCy\n  description: |\n    This package provides spaCy components and architectures to use transformer\n    models via Hugging Face's transformers in spaCy. The result is convenient\n    access to state-of-the-art transformer architectures, such as BERT, GPT-2,\n    XLNet, etc.\n  doc_url: https://github.com/explosion/spacy-transformers\n  dev_url: https://github.com/explosion/spacy-transformers\n\nextra:\n  recipe-maintainers:\n    - honnibal\n    - ines\n    - adrianeboyd\n",
 "req": {
  "__set__": true,
  "elements": [
   "pip",
   "python",
   "pytorch",
   "spacy",
   "spacy-alignments",
   "srsly",
   "transformers"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python",
    "pytorch",
    "spacy",
    "spacy-alignments",
    "srsly",
    "transformers"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "smithy_version": "3.18.0",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python >=3.6"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "python >=3.6",
    "pytorch >=1.6.0",
    "spacy >=3.1.3,<4.0.0",
    "spacy-alignments >=0.7.2,<1.0.0",
    "srsly >=2.4.0,<3.0.0",
    "transformers >=3.4.0,<4.12.0"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": "https://pypi.io/packages/source/s/spacy-transformers/spacy-transformers-1.1.4.tar.gz",
 "version": "1.1.4"
}