{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/897572170.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.1.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/919632423.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.1.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/932611335.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.2.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/934671450.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.2.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/957106396.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.2.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/966231234.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.2.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/994644582.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.3.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": "make_graph: render error No module named 'toml'\nTraceback (most recent call last):\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/feedstock_parser.py\", line 241, in populate_feedstock_attributes\n    parse_meta_yaml(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 167, in parse_meta_yaml\n    return _parse_meta_yaml_impl(\n  File \"/home/runner/work/autotick-bot/autotick-bot/cf-scripts/conda_forge_tick/utils.py\", line 239, in _parse_meta_yaml_impl\n    m = MetaData(tmpdir, config=config, variant=var)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 932, in __init__\n    self.parse_again(permit_undefined_jinja=True, allow_no_other_outputs=True)\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1007, in parse_again\n    self.meta = parse(self._get_contents(permit_undefined_jinja,\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/metadata.py\", line 1546, in _get_contents\n    from conda_build.jinja_context import context_processor, UndefinedNeverFail, FilteredLoader\n  File \"/usr/share/miniconda3/envs/run_env/lib/python3.9/site-packages/conda_build/jinja_context.py\", line 13, in <module>\n    import toml\nModuleNotFoundError: No module named 'toml'\n",
 "branch": "main",
 "conda-forge.yml": {
  "bot": {
   "automerge": true
  }
 },
 "feedstock_name": "optimum",
 "hash_type": "sha256",
 "name": "optimum",
 "new_version": "1.3.0",
 "new_version_attempts": {
  "1.1.0": 1,
  "1.1.1": 1,
  "1.2.0": 1,
  "1.2.1": 1,
  "1.2.2": 2,
  "1.2.3": 1,
  "1.3.0": 1
 },
 "new_version_errors": {},
 "outputs_names": {
  "__set__": true,
  "elements": [
   "optimum"
  ]
 },
 "pinning_version": "2022.07.12.16.49.31",
 "pre_pr_migrator_attempts": {},
 "pre_pr_migrator_status": {},
 "raw_meta_yaml": "{% set name = \"optimum\" %}\n{% set version = \"1.3.0\" %}\n\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/optimum-{{ version }}.tar.gz\n  sha256: e68a7a075571cfadf3eaa02513cfdd315f750ce01e8ed5b8d3b4ce785b5c9c7d\n\nbuild:\n  number: 0\n  noarch: python\n  script:\n    - {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python >=3.7\n  run:\n    - python >=3.7\n    - coloredlogs\n    - sympy\n    - pytorch >=1.9\n    - transformers >=4.15.0\n    - huggingface_hub ==0.4.0\n    - packaging\n    - numpy\n    - requests\n    - tqdm\n    - pyyaml\n    # Dependencies necessary for passing pip-check\n    - onnx\n    - onnxruntime\n    - datasets >=1.2.1\n    - dill >=0.3.5.1\n\ntest:\n  imports:\n    - optimum\n  commands:\n    - pip check\n  requires:\n    - pip\n\nabout:\n  home: https://huggingface.co/hardware\n  summary: |\n    Optimum Library is an extension of the Hugging Face Transformers \n    library, providing a framework to integrate third-party libraries \n    from Hardware Partners and interface with their specific functionality.\n  license: Apache-2.0\n  license_file: LICENSE\n  description: |\n    \uD83E\uDD17 Optimum is an extension of \uD83E\uDD17 Transformers, providing a set of performance \n    optimization tools enabling maximum efficiency to train and run models on \n    targeted hardware.\n\n    The AI ecosystem evolves quickly and more and more specialized hardware along \n    with their own optimizations are emerging every day. As such, Optimum enables \n    users to efficiently use any of these platforms with the same ease inherent \n    to transformers.\n\n    PyPI: [https://pypi.org/project/optimum/](https://pypi.org/project/optimum/)\n\n  doc_url: https://huggingface.co/docs/optimum/\n  dev_url: https://github.com/huggingface/optimum\n\nextra:\n  recipe-maintainers:\n    - sugatoray\n",
 "smithy_version": "3.21.0",
 "strong_exports": false,
 "url": "https://pypi.io/packages/source/o/optimum/optimum-1.3.0.tar.gz",
 "version": "1.3.0"
}