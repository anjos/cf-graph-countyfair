{
 "PRed": [
  {
   "PR": {
    "__lazy_json__": "pr_json/464856127.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.3.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/471866466.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.3.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/490009778.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/497147344.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/519094294.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.2"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/525044675.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.4.3"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/529933638.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.5.0"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR": {
    "__lazy_json__": "pr_json/552052174.json"
   },
   "data": {
    "bot_rerun": false,
    "migrator_name": "Version",
    "migrator_version": 0,
    "version": "1.5.1"
   },
   "keys": [
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived": false,
 "bad": false,
 "branch": "master",
 "conda-forge.yml": {},
 "feedstock_name": "adversarial-robustness-toolbox",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox",
   "doc_url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Documentation",
   "home": "https://github.com/Trusted-AI/adversarial-robustness-toolbox",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": "LICENSE",
   "summary": "Toolbox for adversarial machine learning."
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "rluria14",
    "oblute",
    "ndmaxar"
   ]
  },
  "package": {
   "name": "adversarial-robustness-toolbox",
   "version": "1.5.1"
  },
  "requirements": {
   "host": [
    "pip",
    "python"
   ],
   "run": [
    "cma",
    "ffmpeg-python",
    "matplotlib-base",
    "mypy",
    "pillow",
    "pydub",
    "kornia",
    "python",
    "resampy",
    "scikit-learn ==0.22.1",
    "scipy ==1.4.1",
    "six",
    "statsmodels",
    "tqdm",
    "tensorflow"
   ]
  },
  "source": {
   "sha256": "dc055025ba5b4236962d4563683e97d1593e66aa1bcc94bcb0bb23612aae64f6",
   "url": "https://pypi.io/packages/source/a/adversarial-robustness-toolbox/adversarial-robustness-toolbox-1.5.1.tar.gz"
  },
  "test": {
   "imports": [
    "art",
    "art.attacks",
    "art.attacks.evasion",
    "art.attacks.evasion.adversarial_patch",
    "art.attacks.evasion.projected_gradient_descent",
    "art.attacks.extraction",
    "art.attacks.inference",
    "art.attacks.poisoning",
    "art.attacks.poisoning.perturbations",
    "art.classifiers",
    "art.classifiers.scikitlearn",
    "art.defences",
    "art.defences.detector",
    "art.defences.detector.evasion",
    "art.defences.detector.evasion.subsetscanning",
    "art.defences.detector.poison",
    "art.defences.postprocessor",
    "art.defences.preprocessor",
    "art.defences.trainer",
    "art.defences.transformer",
    "art.estimators",
    "art.estimators.certification",
    "art.estimators.certification.randomized_smoothing",
    "art.estimators.classification",
    "art.estimators.encoding",
    "art.estimators.generation",
    "art.estimators.object_detection",
    "art.estimators.regression",
    "art.metrics",
    "art.wrappers",
    "tests",
    "tests.attacks",
    "tests.attacks.evasion",
    "tests.attacks.inference",
    "tests.classifiersFrameworks",
    "tests.defences",
    "tests.defences.detector",
    "tests.defences.detector.evasion",
    "tests.defences.detector.evasion.subsetscanning",
    "tests.defences.detector.poison",
    "tests.estimators",
    "tests.estimators.certification",
    "tests.estimators.classification",
    "tests.metrics",
    "tests.wrappers"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cma",
    "ffmpeg-python",
    "kornia",
    "matplotlib-base",
    "mypy",
    "pillow",
    "pydub",
    "python",
    "resampy",
    "scikit-learn",
    "scipy",
    "six",
    "statsmodels",
    "tensorflow",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "dev_url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox",
   "doc_url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Documentation",
   "home": "https://github.com/Trusted-AI/adversarial-robustness-toolbox",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": "LICENSE",
   "summary": "Toolbox for adversarial machine learning."
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/usr/share/miniconda/envs/run_env/conda-bld/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/bin/python -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "rluria14",
    "oblute",
    "ndmaxar"
   ]
  },
  "package": {
   "name": "adversarial-robustness-toolbox",
   "version": "1.5.1"
  },
  "requirements": {
   "host": [
    "pip",
    "python"
   ],
   "run": [
    "cma",
    "ffmpeg-python",
    "matplotlib-base",
    "mypy",
    "pillow",
    "pydub",
    "kornia",
    "python",
    "resampy",
    "scikit-learn ==0.22.1",
    "scipy ==1.4.1",
    "six",
    "statsmodels",
    "tqdm",
    "tensorflow"
   ]
  },
  "source": {
   "sha256": "dc055025ba5b4236962d4563683e97d1593e66aa1bcc94bcb0bb23612aae64f6",
   "url": "https://pypi.io/packages/source/a/adversarial-robustness-toolbox/adversarial-robustness-toolbox-1.5.1.tar.gz"
  },
  "test": {
   "imports": [
    "art",
    "art.attacks",
    "art.attacks.evasion",
    "art.attacks.evasion.adversarial_patch",
    "art.attacks.evasion.projected_gradient_descent",
    "art.attacks.extraction",
    "art.attacks.inference",
    "art.attacks.poisoning",
    "art.attacks.poisoning.perturbations",
    "art.classifiers",
    "art.classifiers.scikitlearn",
    "art.defences",
    "art.defences.detector",
    "art.defences.detector.evasion",
    "art.defences.detector.evasion.subsetscanning",
    "art.defences.detector.poison",
    "art.defences.postprocessor",
    "art.defences.preprocessor",
    "art.defences.trainer",
    "art.defences.transformer",
    "art.estimators",
    "art.estimators.certification",
    "art.estimators.certification.randomized_smoothing",
    "art.estimators.classification",
    "art.estimators.encoding",
    "art.estimators.generation",
    "art.estimators.object_detection",
    "art.estimators.regression",
    "art.metrics",
    "art.wrappers",
    "tests",
    "tests.attacks",
    "tests.attacks.evasion",
    "tests.attacks.inference",
    "tests.classifiersFrameworks",
    "tests.defences",
    "tests.defences.detector",
    "tests.defences.detector.evasion",
    "tests.defences.detector.evasion.subsetscanning",
    "tests.defences.detector.poison",
    "tests.estimators",
    "tests.estimators.certification",
    "tests.estimators.classification",
    "tests.metrics",
    "tests.wrappers"
   ]
  }
 },
 "name": "adversarial-robustness-toolbox",
 "new_version": "1.5.1",
 "new_version_attempts": {
  "1.3.2": 1,
  "1.3.3": 1,
  "1.4.0": 1,
  "1.4.1": 1,
  "1.4.2": 1,
  "1.4.3": 1,
  "1.5.0": 1,
  "1.5.1": 1
 },
 "new_version_errors": {},
 "outputs_names": {
  "__set__": true,
  "elements": [
   "adversarial-robustness-toolbox"
  ]
 },
 "pinning_version": "2021.01.08.18.10.03",
 "raw_meta_yaml": "{% set name = \"adversarial-robustness-toolbox\" %}\n{% set version = \"1.5.1\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: dc055025ba5b4236962d4563683e97d1593e66aa1bcc94bcb0bb23612aae64f6\n\nbuild:\n  number: 0\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python\n  run:\n    - cma\n    - ffmpeg-python\n    - matplotlib-base\n    - mypy\n    - pillow\n    - pydub\n    - kornia\n    - python\n    - resampy\n    - scikit-learn ==0.22.1\n    - scipy ==1.4.1\n    - six\n    - statsmodels\n    - tqdm\n    - tensorflow\n\ntest:\n  imports:\n    - art\n    - art.attacks\n    - art.attacks.evasion\n    - art.attacks.evasion.adversarial_patch\n    - art.attacks.evasion.projected_gradient_descent\n    - art.attacks.extraction\n    - art.attacks.inference\n    - art.attacks.poisoning\n    - art.attacks.poisoning.perturbations\n    - art.classifiers\n    - art.classifiers.scikitlearn\n    - art.defences\n    - art.defences.detector\n    - art.defences.detector.evasion\n    - art.defences.detector.evasion.subsetscanning\n    - art.defences.detector.poison\n    - art.defences.postprocessor\n    - art.defences.preprocessor\n    - art.defences.trainer\n    - art.defences.transformer\n    - art.estimators\n    - art.estimators.certification\n    - art.estimators.certification.randomized_smoothing\n    - art.estimators.classification\n    - art.estimators.encoding\n    - art.estimators.generation\n    - art.estimators.object_detection\n    - art.estimators.regression\n    - art.metrics\n    - art.wrappers\n    - tests\n    - tests.attacks\n    - tests.attacks.evasion\n    - tests.attacks.inference\n    - tests.classifiersFrameworks\n    - tests.defences\n    - tests.defences.detector\n    - tests.defences.detector.evasion\n    - tests.defences.detector.evasion.subsetscanning\n    - tests.defences.detector.poison\n    - tests.estimators\n    - tests.estimators.certification\n    - tests.estimators.classification\n    - tests.metrics\n    - tests.wrappers\n\nabout:\n  home: https://github.com/Trusted-AI/adversarial-robustness-toolbox\n  license: MIT\n  license_family: MIT\n  license_file: LICENSE\n  summary: Toolbox for adversarial machine learning.\n  doc_url: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Documentation\n  dev_url: https://github.com/Trusted-AI/adversarial-robustness-toolbox\n\nextra:\n  recipe-maintainers:\n    - rluria14\n    - oblute\n    - ndmaxar\n",
 "req": {
  "__set__": true,
  "elements": [
   "cma",
   "ffmpeg-python",
   "kornia",
   "matplotlib-base",
   "mypy",
   "pillow",
   "pip",
   "pydub",
   "python",
   "resampy",
   "scikit-learn",
   "scipy",
   "six",
   "statsmodels",
   "tensorflow",
   "tqdm"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cma",
    "ffmpeg-python",
    "kornia",
    "matplotlib-base",
    "mypy",
    "pillow",
    "pydub",
    "python",
    "resampy",
    "scikit-learn",
    "scipy",
    "six",
    "statsmodels",
    "tensorflow",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "smithy_version": "3.8.6",
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cma",
    "ffmpeg-python",
    "kornia",
    "matplotlib-base",
    "mypy",
    "pillow",
    "pydub",
    "python",
    "resampy",
    "scikit-learn ==0.22.1",
    "scipy ==1.4.1",
    "six",
    "statsmodels",
    "tensorflow",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": "https://pypi.io/packages/source/a/adversarial-robustness-toolbox/adversarial-robustness-toolbox-1.5.1.tar.gz",
 "version": "1.5.1"
}